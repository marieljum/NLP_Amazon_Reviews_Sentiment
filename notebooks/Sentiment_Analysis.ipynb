{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf79bba4-138d-4937-810a-99ac2354ed4c",
   "metadata": {},
   "source": [
    "# Sentiment Analysis Using Various Approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66c1d2d-5190-4a5b-a4dd-08e620fd81f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import json\n",
    "import time\n",
    "import re\n",
    "import seaborn as sns\n",
    "\n",
    "# Text cleaning\n",
    "from nltk import sent_tokenize, word_tokenize, regexp_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import spacy \n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# NLTK Bing Liu Lexicon \n",
    "import nltk\n",
    "# nltk.download('opinion_lexicon')\n",
    "from nltk.corpus import opinion_lexicon\n",
    "from nltk.tokenize import word_tokenize \n",
    "\n",
    "# VADER \n",
    "import nltk\n",
    "# nltk.download('vader_lexicon')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "# Supervised learning \n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score, roc_curve\n",
    "from sklearn.calibration import CalibrationDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline \n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse import hstack, vstack\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad46dc4d-99a0-42a2-86e1-2be2a26e242b",
   "metadata": {},
   "source": [
    "## Loading a subset of reviews and meta data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30beeb6b-563d-4b90-aeed-7ad12b45e2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1 \n",
    "total_rows = 0\n",
    "\n",
    "def process_chunks(file, chunksize = 1000):\n",
    "    \"\"\"\n",
    "    Processes chunks of records from a JSON Lines file and appends them to a DataFrame.\n",
    "    \n",
    "    This function reads a JSON Lines file in chunks of a specified size, appends each chunk to a list of DataFrames, \n",
    "    and prints the number of rows added after processing each chunk. It stops after processing a maximum of 10 chunks.\n",
    "    \n",
    "    Parameters:\n",
    "    file (str): The path to the JSON Lines file to be processed.\n",
    "    chunksize (int): The number of records per chunk. Default is 1000.\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: A DataFrame containing all the processed chunks concatenated together.\n",
    "    \"\"\"\n",
    "\n",
    "    # Setting as global variables\n",
    "    global n, total_rows  \n",
    "    \n",
    "    chunks = pd.read_json(file, lines=True, chunksize = chunksize)\n",
    "    dfs = []  \n",
    "    n_chunks = 0\n",
    "\n",
    "    for chunk in chunks:\n",
    "        dfs.append(chunk)\n",
    "        n_chunks += 1  \n",
    "        print(len(chunk), \" rows added\")\n",
    "        n += 1 \n",
    "        total_rows += len(chunk)\n",
    "        if n_chunks >= 10:  \n",
    "            break  \n",
    "            \n",
    "    print(\"Done\")\n",
    "    print(f\"Total rows: {total_rows}\")\n",
    "    return pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a6d07d-3148-430b-be2f-6889f87b8375",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reviews = \"../data/Home_and_Kitchen.jsonl\"\n",
    "meta = \"../data/meta_Home_and_Kitchen.jsonl\"\n",
    "\n",
    "start = time.process_time()\n",
    "\n",
    "reviews_subset = process_chunks(reviews)\n",
    "\n",
    "end = time.process_time()\n",
    "elapsed_time = end - start\n",
    "print('Created a subset of the reviews dataset')\n",
    "print('Execution time:', elapsed_time, 'seconds')\n",
    "\n",
    "print('--------------')\n",
    "start = time.process_time()\n",
    "\n",
    "meta_subset = process_chunks(meta)\n",
    "\n",
    "end = time.process_time()\n",
    "elapsed_time = end - start\n",
    "print('Created a subset of the meta dataset')\n",
    "print('Execution time:', elapsed_time, 'seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4824a8-b9ea-43cf-a93c-e2d2f9bac0bc",
   "metadata": {},
   "source": [
    "## Text Cleaning - spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58cb3820-3f0d-4d8c-bfdf-bb545d1b81e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = spacy.lang.en.stop_words.STOP_WORDS\n",
    "print('Original stopwords count:', len(stop_words))\n",
    "\n",
    "# Updating my stopwords list \n",
    "stop_words = spacy.lang.en.stop_words.STOP_WORDS\n",
    "\n",
    "# Include/ exclude certain words\n",
    "include_stopwords = {'would'}\n",
    "exclude_stopwords = {'well', 'off', 'very', 'not', 'few', 'much'}\n",
    "\n",
    "stop_words |= include_stopwords\n",
    "stop_words -= exclude_stopwords\n",
    "\n",
    "# Remove adjectives from my stopwords using spaCy\n",
    "exclude_adjectives = {word for word in stop_words if nlp(word)[0].pos_ == \"ADJ\"}\n",
    "print(exclude_adjectives)\n",
    "\n",
    "stop_words -= exclude_adjectives\n",
    "print('Stopwords count:', len(stop_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4409d870-e176-4674-8a86-7a60bc28fc22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(doc):\n",
    "    \"\"\"\n",
    "    Cleans and preprocesses a text document using spaCy.\n",
    "    \n",
    "    This function takes a text document as input, converts it to lowercase, \n",
    "    lemmatizes the words, removes non-alphabetic characters, and filters out stopwords. \n",
    "    The resulting cleaned text is returned as a single string. \n",
    "    \"\"\"\n",
    "    doc = doc.lower()\n",
    "    doc = nlp(doc)\n",
    "    # Lemmatize words \n",
    "    lemmas = [token.lemma_ for token in doc]\n",
    "    # Removing non-alphabetic characters and stopwords\n",
    "    tokens = [lemma for lemma in lemmas if lemma.isalpha() and lemma not in stop_words]\n",
    "    cleaned_doc = \" \".join(tokens)\n",
    "    \n",
    "    return cleaned_doc\n",
    "\n",
    "cleaned_text = reviews_subset.copy()\n",
    "cleaned_text['spacy_text'] = cleaned_text['text'].apply(clean_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808f0a04-9199-4976-84bd-241c4d687637",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Remove observations that are empty after the cleaning step\n",
    "cleaned_text = cleaned_text[cleaned_text['spacy_text'].str.len() != 0]\n",
    "print('Record count:', len(cleaned_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3281f8c-b103-4cdc-81e3-8a49fd7eb37a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "i = 2\n",
    "print(f'Title: {cleaned_text.loc[i,\"title\"]}\\n')\n",
    "\n",
    "print(f'Text: {cleaned_text.loc[i,\"text\"]}\\n')\n",
    "\n",
    "print(f'Text: {cleaned_text.loc[i,\"spacy_text\"]}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c9792e-4dae-450b-8484-08e4f43a0b24",
   "metadata": {},
   "source": [
    "## Export Subset Dataset with Cleaned Text Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c788e82-8959-4b92-a01d-b1d780a656cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_text.to_csv('../data/cleaned_subset.csv', index = False)\n",
    "meta_subset.to_csv('../data/meta_subset.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e2b460-9175-483a-bc8a-ee691ff89e61",
   "metadata": {},
   "source": [
    "## Feature Engineering \n",
    "\n",
    "Create new features: word count, average word length, exclamation mark count, and sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b41804b-742d-4359-84e4-7a998dd67937",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_count(text):\n",
    "    \"\"\"\n",
    "    Counts the number of words in the text.\n",
    "    \"\"\"\n",
    "    words = text.split()\n",
    "    return len(words)\n",
    "\n",
    "\n",
    "def avg_word_length(text):\n",
    "    \"\"\"\n",
    "    Returns the average word length in the text. \n",
    "    \"\"\"\n",
    "    # Check for empty or white-space only string \n",
    "    if not text.strip():\n",
    "        return 0\n",
    "        \n",
    "    words = text.split()\n",
    "    if not words:  # Check if words list is empty\n",
    "        return 0\n",
    "        \n",
    "    word_lengths = [len(word) for word in words]\n",
    "    avg_word_length = sum(word_lengths)/len(words)\n",
    "    \n",
    "    return(avg_word_length) \n",
    "\n",
    "\n",
    "def exclamation_count(text):\n",
    "    \"\"\"\n",
    "    Returns the number of exclamations in the text.\n",
    "    \"\"\"\n",
    "    doc = nlp(text)\n",
    "    exclamations = []\n",
    "    for token in doc: \n",
    "        if token.text == '!':\n",
    "            exclamations.append(token.text)\n",
    "    return len(exclamations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cadd99cb-3c64-49dd-a247-8ad31b382a70",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cleaned_text['word_count'] = cleaned_text['text'].apply(word_count)\n",
    "cleaned_text['avg_word_length'] = cleaned_text['text'].apply(avg_word_length)\n",
    "cleaned_text['exclamation_count'] = cleaned_text['text'].apply(exclamation_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a3ea48-5387-49ea-8fa3-ae897b7711be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cleaned_text[['text', 'word_count', 'avg_word_length', 'exclamation_count']].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12410e81-428e-42a6-962e-e84c02756280",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_text['word_count'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de132a3-2403-4e1d-bdf8-59112dc9813d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(cleaned_text['word_count'],bins=25);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc842d5-18fc-4330-9d6d-e82c0e405858",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(cleaned_text['exclamation_count'],bins=25);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df3e4a3-f3f1-4bf8-8a4f-768fde628eec",
   "metadata": {},
   "source": [
    "## Sentiment Analysis with Lexicons\n",
    "\n",
    "Unsupervised learning approach that involves evaluating the sentiment scores of words in a document based on predefined lexicons. A lexicon is a dictionary that contains a collection of words that is categorized as positive, negative, and neutral by experts. Each word's sentiment is determined, and the scores are combined to calculate the overall sentiment of the sentence. \n",
    "- Disadvantages: words that are not in the lexicon will not be scored; some lexicons might be better suited for a specific use; it overlooks negation (lexicons only match words and not phrases, ie \"not bad\" is scored more negative instead of neutral)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a4d30c-c991-4605-be1f-c9b401061210",
   "metadata": {},
   "source": [
    "### Bing Liu Lexicon\n",
    "\n",
    "The Bing Liu lexicon has a total of 6, 786 words with 2,005 classified as positive and 4,781 as negative. CLassification is binary (positive or negative)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5887a47-ad06-4241-b7ce-5fa7f40bd806",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Total number of words in opinion lexicon', len(opinion_lexicon.words()))\n",
    "print('Examples of positive words:', opinion_lexicon.positive()[:10])\n",
    "print('Examples of negative words:', opinion_lexicon.negative()[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e75ef3-dbe2-493f-86a5-91a5a010d001",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_score = 1\n",
    "neg_score = -1\n",
    "word_dict = {}\n",
    "\n",
    "# Adding the positive words to the dictionary\n",
    "for word in opinion_lexicon.positive():\n",
    "    word_dict[word] = pos_score \n",
    "\n",
    "# Adding the negative words to the dictionary \n",
    "for word in opinion_lexicon.negative():\n",
    "    word_dict[word] = neg_score \n",
    "\n",
    "def bing_liu_score(text):\n",
    "    sentiment_score = 0 \n",
    "    bag_of_words = word_tokenize(text.lower())\n",
    "\n",
    "    # Check if bag_of_words is empty\n",
    "    if bag_of_words: \n",
    "        for word in bag_of_words: \n",
    "            if word in word_dict: \n",
    "                sentiment_score += word_dict[word]\n",
    "        return sentiment_score / len(bag_of_words)\n",
    "    else: \n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a39dd6-e6a5-4996-9102-8a7131a4cc02",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cleaned_text['Bing_Liu_score'] = cleaned_text['text'].apply(bing_liu_score)\n",
    "cleaned_text['Bing_Liu_spaCy'] = cleaned_text['spacy_text'].apply(bing_liu_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4291b896-3b1b-4c16-bd45-0d7890b08f86",
   "metadata": {},
   "source": [
    "### VADER Lexicon\n",
    "Rule-based lexicon. \n",
    "9,000 features with scales of [-4] Extremely Negative to [4] Extremely Positive with [0] for Neutral or Neither. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e75ea6-5546-46fa-b399-9bb22534db27",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40cf930-a5ad-446a-a2d3-99f612ff4af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vader_score(text):\n",
    "    score = model.polarity_scores(text)\n",
    "    compound_score = score['compound']\n",
    "    return compound_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8627a1c6-8041-43a4-9498-df156b9c876c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cleaned_text['Vader_score'] = cleaned_text['text'].apply(vader_score)\n",
    "cleaned_text['Vader_spaCy'] = cleaned_text['spacy_text'].apply(vader_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf559f7-1a5a-4040-a35c-998d4f083f2c",
   "metadata": {},
   "source": [
    "### Lexicon Sentiment Accuracy Scores "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09db1302-dad3-4cb5-ad16-e4cc7acaffd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_text[['Bing_Liu_score', 'Bing_Liu_spaCy', 'Vader_score', 'Vader_spaCy']].sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc64278e-05c5-4666-93dd-788f93858bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate mean sentiment score for each rating category\n",
    "mean_scores = cleaned_text.groupby('rating').agg({\n",
    "    'Bing_Liu_score':'mean',\n",
    "    'Bing_Liu_spaCy': 'mean',\n",
    "    'Vader_score': 'mean',\n",
    "    'Vader_spaCy': 'mean'\n",
    "}).reset_index()\n",
    "\n",
    "print(mean_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af0e602-ab3f-44a4-b504-b0bc6917462e",
   "metadata": {},
   "source": [
    "## Sentiment Analysis - Supervised Learning Approach\n",
    "\n",
    "Using supervised learning models, we will classify the sentiment of a review based on pre-processed text from spaCy. Reviews will be classified as positive or negative sentiment based on their ratings:\n",
    "- Positive (1): records with ratings of 4 and 5.\n",
    "- Negative (0): records with ratings of 1 and 2.\n",
    "- Neutral: records with ratings of 3 are removed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a401e7-3234-46fe-87ab-52d0b9c5999d",
   "metadata": {},
   "source": [
    "### Feature Engineering: Sentiment Classification\n",
    "Create a new column in our dataset to classify records based on our ratings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b6186d-b903-4629-918e-eb4202fa8b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_text['sentiment'] = 0\n",
    "\n",
    "# Classify records with rating higher than a 3, positive (1)\n",
    "cleaned_text.loc[cleaned_text['rating'] > 3, 'sentiment'] = 1\n",
    "\n",
    "# Classify records with rating lower than a 3, negative (0)\n",
    "cleaned_text.loc[cleaned_text['rating'] < 3, 'sentiment'] = 0\n",
    "\n",
    "# Remove records with a rating of 3\n",
    "cleaned_text = cleaned_text.loc[cleaned_text['rating'] != 3].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f256a0b-d891-4f51-bfa6-066fd99e27a7",
   "metadata": {},
   "source": [
    "### Text Vectorization with TF-IDF\n",
    "Use TF-IDF vectorizer to transform the text into vectors based on the frequency of words in the text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0803a5db-c674-45f5-aca2-9b50b466abde",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "clf = MultinomialNB()\n",
    "\n",
    "pipe = Pipeline([(\"tfidf\", tfidf), (\"clf\", clf)])\n",
    "\n",
    "param_grid = {\n",
    "    'tfidf__ngram_range':[(1,1), (1,2), (1,3)],\n",
    "    'tfidf__min_df':[1, 2, 5, 10, 20],\n",
    "    'clf__fit_prior':[False, True]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2445f1-b528-4359-80b5-56f4bafea75b",
   "metadata": {},
   "source": [
    "### Model training and Evaluation\n",
    "The following models will be used in our analysis:\n",
    "- Logistic Regression: a linear model for binary classification.\n",
    "- Linear Support Vector Classification (SVC): A classifier that constructs a hyperplane to separate classes.\n",
    "- Randomized Search Cross-Validation: A technique to tune hyperparameters for improving model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb3915c-c8ba-41ee-bb30-d496d9db0fd3",
   "metadata": {},
   "source": [
    "#### Randomized Search Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbaec5eb-cf1b-43d2-a74d-12ecf4f358f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = cleaned_text[['spacy_text']]\n",
    "y = cleaned_text['sentiment']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 42, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c993a49f-5766-4312-a72d-5dcaf117959d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rs = RandomizedSearchCV(estimator = pipe, param_distributions = param_grid, verbose = 2, n_jobs = -1)\n",
    "rs.fit(X_train['spacy_text'], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec48043-0d29-460b-8f3a-f08b4b35cfa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rs.predict(X_test['spacy_text'])\n",
    "\n",
    "print(f'Accuracy: {accuracy_score(y_test, y_pred)}')\n",
    "print(f'ROC-AUC Score: {roc_auc_score(y_test, y_pred)}')\n",
    "print(f'Classification Report: \\n {classification_report(y_test,y_pred, zero_division = 0.0)}')\n",
    "print(f'Confusion Matrix: \\n {confusion_matrix(y_test, y_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19778ff-0d0c-4f66-b573-a251b0eb71ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the best parameters \n",
    "print(rs.best_params_)\n",
    "print(rs.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa6abe1-983a-4f26-96b8-0d960184d850",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_prob = rs.predict_proba(X_test['spacy_text'])\n",
    "positive_class_prob = sentiment_prob[:, 1]\n",
    "\n",
    "# Calculate ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, positive_class_prob, pos_label=1)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Randomized Search Cross Validation ROC Curve')\n",
    "plt.show()\n",
    "\n",
    "print(roc_auc_score(y_test, positive_class_prob))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294ced2c-5fe7-4c77-b226-7e878a47cb92",
   "metadata": {},
   "source": [
    "#### Compare trained model to baseline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1778df-2d9d-4cf6-b26a-b6afb29c5be7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dummy_clf = DummyClassifier(strategy = 'most_frequent')\n",
    "dummy_clf.fit(X_train, y_train)\n",
    "y_pred_baseline = dummy_clf.predict(X_test)\n",
    "\n",
    "print(f'Accuracy: {accuracy_score(y_test, y_pred_baseline)}')\n",
    "print(f'ROC-AUC Score: {roc_auc_score(y_test, y_pred_baseline)}')\n",
    "print(f'Classification Report: \\n {classification_report(y_test,y_pred_baseline, zero_division = 0.0)}')\n",
    "print(f'Confusion Matrix: \\n {confusion_matrix(y_test, y_pred_baseline)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb70a50c-4159-4566-aa14-668a0a619a15",
   "metadata": {},
   "source": [
    "The trained randomized search cross validation model performs slightly beter than the baseline model.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3c2d22-5ad5-4795-a801-69a91c2e44da",
   "metadata": {},
   "source": [
    "#### Linear Support Vector Classification (SVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21bd5f07-fd4c-49dc-a404-e30f2faa3254",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(min_df = 5, ngram_range = (1,2))\n",
    "\n",
    "X_train_tf = tfidf.fit_transform(X_train['spacy_text'])\n",
    "X_test_tf = tfidf.transform(X_test['spacy_text'])\n",
    "\n",
    "linear = LinearSVC(random_state = 42, tol = 1e-5, max_iter = 10000)\n",
    "linear.fit(X_train_tf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd6dfe9-da5c-4585-84f6-92104737f72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = linear.predict(X_test_tf)\n",
    "\n",
    "print(f'Accuracy: {accuracy_score(y_test, y_pred)}')\n",
    "print(f'ROC-AUC Score: {roc_auc_score(y_test, y_pred)}')\n",
    "print(f'Classification Report: \\n {classification_report(y_test,y_pred, zero_division = 0.0)}')\n",
    "print(f'Confusion Matrix: \\n {confusion_matrix(y_test, y_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de24121-1863-45ad-9325-0ceb4833d0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(4, 4))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9fbae27-0c2a-48a2-a2d1-5369f60989c4",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d408732c-5c48-432d-a38d-51a45be5c840",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_log = TfidfVectorizer(min_df = 10, ngram_range = (1,3))\n",
    "\n",
    "X_train_tf = tfidf_log.fit_transform(X_train['spacy_text'])\n",
    "X_test_tf = tfidf_log.transform(X_test['spacy_text'])\n",
    "\n",
    "logreg = LogisticRegression(max_iter = 1000).fit(X_train_tf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35841c1-b8bb-4a2d-ba53-a4323e4a01c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = logreg.predict(X_test_tf)\n",
    "\n",
    "print(f'Accuracy: {accuracy_score(y_test, y_pred)}')\n",
    "print(f'ROC-AUC Score: {roc_auc_score(y_test, y_pred)}')\n",
    "print(f'Classification Report: \\n {classification_report(y_test,y_pred, zero_division = 0.0)}')\n",
    "print(f'Confusion Matrix: \\n {confusion_matrix(y_test, y_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9ad3d8-f652-4b6d-9081-6e852c5c670d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "features = None\n",
    "features = tfidf_log.get_feature_names_out(features)\n",
    "\n",
    "sentiment = 0\n",
    "idx = list(logreg.classes_).index(sentiment)\n",
    "\n",
    "\n",
    "# # Extract coefficients from the Logistic Regression model \n",
    "intercept = logreg.intercept_[idx]\n",
    "coefficients = logreg.coef_[idx]\n",
    "\n",
    "coefficients_df = pd.DataFrame({\n",
    "    'variable': ['intercept'] + list(features),\n",
    "    'coefficient': [intercept] + list(coefficients)\n",
    "})\n",
    "\n",
    "coefficients_df.sort_values(by = 'coefficient', ascending = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9afe1764-c30e-4429-ad42-8450ff1c2c06",
   "metadata": {},
   "source": [
    "### Train-Test Split with Other Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515a6d4f-2c36-4895-9eec-1ccef8639a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_text.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34fea75-ab28-41e4-958a-827e438b0231",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = ['rating', 'helpful_vote', 'verified_purchase', 'word_count', 'avg_word_length', \n",
    "            'exclamation_count', 'spacy_text', 'Bing_Liu_score', 'Bing_Liu_spaCy', 'Vader_score', 'Vader_spaCy']\n",
    "X = cleaned_text[variables]\n",
    "y = cleaned_text['sentiment']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 42, stratify = y)\n",
    "\n",
    "print ('Size of Training Data: ', X_train.shape[0])\n",
    "print ('Size of Test Data: ', X_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3883c4e6-5628-4811-8222-b50b2e55aa51",
   "metadata": {},
   "source": [
    "### Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63c7731-ed8d-4a4b-b1d0-664396bcc247",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = ['helpful_vote', 'verified_purchase', 'word_count', 'avg_word_length', \n",
    "            'exclamation_count', 'Bing_Liu_score', 'Bing_Liu_spaCy', 'Vader_score', 'Vader_spaCy']\n",
    "X_train[variables].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1464a1-d301-4797-99ce-039fcc74b8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = csr_matrix(X_train[variables].astype(float))\n",
    "n = csr_matrix(X_test[variables].astype(float))\n",
    "\n",
    "X_train_stack = hstack((m, X_train_tf))\n",
    "X_test_stack = hstack((n, X_test_tf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2645f79c-007d-477f-a488-cffb34f6c895",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear.fit(X_train_stack, y_train)\n",
    "\n",
    "y_pred = linear.predict(X_test_stack)\n",
    "\n",
    "print(f'Accuracy: {accuracy_score(y_test, y_pred)}')\n",
    "print(f'ROC-AUC Score: {roc_auc_score(y_test, y_pred)}')\n",
    "print(f'Classification Report: \\n {classification_report(y_test,y_pred, zero_division = 0.0)}')\n",
    "print(f'Confusion Matrix: \\n {confusion_matrix(y_test, y_pred)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
