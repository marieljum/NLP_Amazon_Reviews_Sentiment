{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf79bba4-138d-4937-810a-99ac2354ed4c",
   "metadata": {},
   "source": [
    "# Sentiment Analysis Using Various Approaches\n",
    "\n",
    "## Lexicon-based approach \n",
    "- Unsupervised learning\n",
    "- Based on calculating sentiment scores of words in a document from lexicons.\n",
    "- Each word's sentiment is determined, and the scores are combined to calculate the overall sentiment of the sentence. \n",
    "- A lexicon is a dictionary that contains a collection of words that is categorized as positive, negative, and neutral by experts. Their scores can change over time.\n",
    "- Only those words listed in the lexicon will actually be scored.\n",
    "- Disadvantages: words that are not in the lexicon will not be scored; some lexicons might be better suited for a specific use; it overlooks negation (lexicons only match words and not phrases, ie \"not bad\" is scored more negative instead of neutral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66c1d2d-5190-4a5b-a4dd-08e620fd81f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import json\n",
    "import time\n",
    "import re\n",
    "import seaborn as sns\n",
    "\n",
    "# Text cleaning\n",
    "from nltk import sent_tokenize, word_tokenize, regexp_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# NLTK Bing Liu Lexicon \n",
    "import nltk\n",
    "# nltk.download('opinion_lexicon')\n",
    "from nltk.corpus import opinion_lexicon\n",
    "from nltk.tokenize import word_tokenize \n",
    "\n",
    "# VADER \n",
    "import nltk\n",
    "# nltk.download('vader_lexicon')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "# Supervised learning \n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline \n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# Text Vectorization\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Topic Modeling \n",
    "from sklearn.decomposition import TruncatedSVD, NMF, LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad46dc4d-99a0-42a2-86e1-2be2a26e242b",
   "metadata": {},
   "source": [
    "## Loading a subset of reviews and meta data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30beeb6b-563d-4b90-aeed-7ad12b45e2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1 \n",
    "total_rows = 0\n",
    "\n",
    "def process_chunks(file, chunksize = 1000):\n",
    "\n",
    "    # Setting as global variables\n",
    "    global n, total_rows  \n",
    "    \n",
    "    chunks = pd.read_json(file, lines=True, chunksize = chunksize)\n",
    "    dfs = []  \n",
    "    n_chunks = 0\n",
    "\n",
    "    for chunk in chunks:\n",
    "        dfs.append(chunk)\n",
    "        n_chunks += 1  # Count the number of chunks processed\n",
    "        print(len(chunk), \" rows added\")\n",
    "        n += 1 \n",
    "        total_rows += len(chunk)\n",
    "        if n_chunks >= 10:  # Process only the first 5 chunks\n",
    "            break  \n",
    "            \n",
    "    print(\"Done\")\n",
    "    print(\"Total rows:\", total_rows)\n",
    "    return pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a6d07d-3148-430b-be2f-6889f87b8375",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reviews = \"../data/Home_and_Kitchen.jsonl\"\n",
    "meta = \"../data/meta_Home_and_Kitchen.jsonl\"\n",
    "\n",
    "start = time.process_time()\n",
    "\n",
    "reviews_subset = process_chunks(reviews)\n",
    "\n",
    "end = time.process_time()\n",
    "elapsed_time = end - start\n",
    "print('Created a subset of the reviews dataset')\n",
    "print('Execution time:', elapsed_time, 'seconds')\n",
    "\n",
    "print('--------------')\n",
    "start = time.process_time()\n",
    "\n",
    "meta_subset = process_chunks(meta)\n",
    "\n",
    "end = time.process_time()\n",
    "elapsed_time = end - start\n",
    "print('Created a subset of the meta dataset')\n",
    "print('Execution time:', elapsed_time, 'seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e2b460-9175-483a-bc8a-ee691ff89e61",
   "metadata": {},
   "source": [
    "## Feature Engineering \n",
    "\n",
    "Create new features: word count, average word length, exclamation mark count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b41804b-742d-4359-84e4-7a998dd67937",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word count\n",
    "def word_count(text):\n",
    "    words = text.split()\n",
    "    return len(words)\n",
    "\n",
    "# Average word length \n",
    "def avg_word_length(text):\n",
    "    \n",
    "    # Check for empty or white-space only string \n",
    "    if not text.strip():\n",
    "        return 0\n",
    "        \n",
    "    words = text.split()\n",
    "    if not words:  # Check if words list is empty\n",
    "        return 0\n",
    "        \n",
    "    word_lengths = [len(word) for word in words]\n",
    "    avg_word_length = sum(word_lengths)/len(words)\n",
    "    \n",
    "    return(avg_word_length) \n",
    "\n",
    "# Exclamation mark count \n",
    "def exclamation_count(text):\n",
    "    doc = nlp(text)\n",
    "    exclamations = []\n",
    "    for token in doc: \n",
    "        if token.text == '!':\n",
    "            exclamations.append(token.text)\n",
    "    return len(exclamations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cadd99cb-3c64-49dd-a247-8ad31b382a70",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cleaned_text['word_count'] = cleaned_text['text'].apply(word_count)\n",
    "cleaned_text['avg_word_length'] = cleaned_text['text'].apply(avg_word_length)\n",
    "cleaned_text['exclamation_count'] = cleaned_text['text'].apply(exclamation_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a3ea48-5387-49ea-8fa3-ae897b7711be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cleaned_text[['text', 'spacy_text', 'word_count', 'avg_word_length', 'exclamation_count']].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12410e81-428e-42a6-962e-e84c02756280",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_text['word_count'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de132a3-2403-4e1d-bdf8-59112dc9813d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.displot(cleaned_text['word_count'],bins=25);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc842d5-18fc-4330-9d6d-e82c0e405858",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.displot(cleaned_text['exclamation_count'],bins=25);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4824a8-b9ea-43cf-a93c-e2d2f9bac0bc",
   "metadata": {},
   "source": [
    "## Text Cleaning - spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58cb3820-3f0d-4d8c-bfdf-bb545d1b81e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy \n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "stop_words = spacy.lang.en.stop_words.STOP_WORDS\n",
    "print('Original stopwords count:', len(stop_words))\n",
    "\n",
    "# Updating my stopwords list \n",
    "stop_words = spacy.lang.en.stop_words.STOP_WORDS\n",
    "\n",
    "# Include/ exclude certain words\n",
    "include_stopwords = {'would', 'I'}\n",
    "exclude_stopwords = {'i', 'well', 'off', 'very', 'not', 'few', 'much'}\n",
    "\n",
    "stop_words |= include_stopwords\n",
    "stop_words -= exclude_stopwords\n",
    "\n",
    "# Remove adjectives from my stopwords using spaCy\n",
    "exclude_adjectives = {word for word in stop_words if nlp(word)[0].pos_ == \"ADJ\"}\n",
    "print(exclude_adjectives)\n",
    "\n",
    "stop_words -= exclude_adjectives\n",
    "print('Stopwords count:', len(stop_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4409d870-e176-4674-8a86-7a60bc28fc22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(doc):\n",
    "    doc = doc.lower()\n",
    "    doc = nlp(doc)\n",
    "    # Lemmatize words \n",
    "    lemmas = [token.lemma_ for token in doc]\n",
    "    # Removing non-alphabetic characters and stopwords\n",
    "    tokens = [lemma for lemma in lemmas if lemma.isalpha() and lemma not in stop_words]\n",
    "    cleaned_doc = \" \".join(tokens)\n",
    "    \n",
    "    return cleaned_doc\n",
    "\n",
    "cleaned_text = reviews_subset.copy()\n",
    "cleaned_text['spacy_text'] = cleaned_text['text'].apply(clean_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3281f8c-b103-4cdc-81e3-8a49fd7eb37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "print(f'Title: {cleaned_text.loc[i,\"title\"]}\\n')\n",
    "\n",
    "print(f'Text: {cleaned_text.loc[i,\"text\"]}\\n')\n",
    "\n",
    "print(f'Text: {cleaned_text.loc[i,\"spacy_text\"]}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a4d30c-c991-4605-be1f-c9b401061210",
   "metadata": {},
   "source": [
    "## Bing Liu Lexicon\n",
    "\n",
    "The Bing Liu lexicon has a total of 6, 786 words with 2,005 classified as positive and 4,781 as negative. CLassification is binary (positive or negative)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5887a47-ad06-4241-b7ce-5fa7f40bd806",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Total number of words in opinion lexicon', len(opinion_lexicon.words()))\n",
    "print('Examples of positive words:', opinion_lexicon.positive()[:10])\n",
    "print('Examples of negative words:', opinion_lexicon.negative()[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e75ef3-dbe2-493f-86a5-91a5a010d001",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_score = 1\n",
    "neg_score = -1\n",
    "word_dict = {}\n",
    "\n",
    "# Adding the positive words to the dictionary\n",
    "for word in opinion_lexicon.positive():\n",
    "    word_dict[word] = pos_score \n",
    "\n",
    "# Adding the negative words to the dictionary \n",
    "for word in opinion_lexicon.negative():\n",
    "    word_dict[word] = neg_score \n",
    "\n",
    "def bing_liu_score(text):\n",
    "    sentiment_score = 0 \n",
    "    bag_of_words = word_tokenize(text.lower())\n",
    "\n",
    "    # Check if bag_of_words is empty\n",
    "    if bag_of_words: \n",
    "        for word in bag_of_words: \n",
    "            if word in word_dict: \n",
    "                sentiment_score += word_dict[word]\n",
    "        return sentiment_score / len(bag_of_words)\n",
    "    else: \n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a39dd6-e6a5-4996-9102-8a7131a4cc02",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cleaned_text['Bing_Liu_score'] = cleaned_text['text'].apply(bing_liu_score)\n",
    "cleaned_text['Bing_Liu_spaCy'] = cleaned_text['spacy_text'].apply(bing_liu_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4291b896-3b1b-4c16-bd45-0d7890b08f86",
   "metadata": {},
   "source": [
    "## VADER Lexicon\n",
    "Rule-based lexicon. \n",
    "9,000 features with scales of [-4] Extremely Negative to [4] Extremely Positive with [0] for Neutral or Neither. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e75ea6-5546-46fa-b399-9bb22534db27",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40cf930-a5ad-446a-a2d3-99f612ff4af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vader_score(text):\n",
    "    score = model.polarity_scores(text)\n",
    "    compound_score = score['compound']\n",
    "    return compound_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8627a1c6-8041-43a4-9498-df156b9c876c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cleaned_text['Vader_score'] = cleaned_text['text'].apply(vader_score)\n",
    "cleaned_text['Vader_spaCy'] = cleaned_text['spacy_text'].apply(vader_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf559f7-1a5a-4040-a35c-998d4f083f2c",
   "metadata": {},
   "source": [
    "## Lexicon Sentiment Accuracy Scores "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09db1302-dad3-4cb5-ad16-e4cc7acaffd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_text[['Bing_Liu_score', 'Bing_Liu_spaCy', 'Vader_score', 'Vader_spaCy']].sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc64278e-05c5-4666-93dd-788f93858bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate mean sentiment score for each rating category\n",
    "mean_scores = cleaned_text.groupby('rating').agg({\n",
    "    'Bing_Liu_score':'mean',\n",
    "    'Bing_Liu_spaCy': 'mean',\n",
    "    'Vader_score': 'mean',\n",
    "    'Vader_spaCy': 'mean'\n",
    "}).reset_index()\n",
    "\n",
    "print(mean_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f69aaa26-8b45-432d-8a14-777349fb8110",
   "metadata": {},
   "source": [
    "## Supervised Learning Approach\n",
    "\n",
    "This step assigns records with ratings of 4 and 5 as positive (1) and ratings of 1 and 2 as negative. Records with ratings of 3, which is considered neutral, is removed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b6186d-b903-4629-918e-eb4202fa8b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assigning a new target class \n",
    "cleaned_text['sentiment'] = 0\n",
    "\n",
    "# Classify records with rating higher than a 3, positive (1)\n",
    "cleaned_text.loc[cleaned_text['rating'] > 3, 'sentiment'] = 1\n",
    "\n",
    "# Classify records with rating lower than a 3, negative (0)\n",
    "cleaned_text.loc[cleaned_text['rating'] < 3, 'sentiment'] = 0\n",
    "\n",
    "# Remove records with a rating of 3\n",
    "cleaned_text = cleaned_text.loc[cleaned_text['rating'] != 3].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808f0a04-9199-4976-84bd-241c4d687637",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove observations that are empty after the cleaning step\n",
    "cleaned_text = cleaned_text[cleaned_text['spacy_text'].str.len() != 0]\n",
    "print('Record count:', len(cleaned_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9afe1764-c30e-4429-ad42-8450ff1c2c06",
   "metadata": {},
   "source": [
    "### Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34fea75-ab28-41e4-958a-827e438b0231",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating train-test split with spacy cleaned text\n",
    "X = cleaned_text[['spacy_text']]\n",
    "y = cleaned_text['sentiment']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 42, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d92946e-dd0c-4963-a758-3aa28b798109",
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Size of Training Data ', X_train.shape[0])\n",
    "print ('Size of Test Data ', X_test.shape[0])\n",
    "print ('Distribution of classes in Training Data :')\n",
    "print ('Positive Sentiment ', str(sum(y_train == 1)/ len(y_train) * 100.0))\n",
    "print ('Negative Sentiment ', str(sum(y_train == 0)/ len(y_train) * 100.0))\n",
    "print ('Distribution of classes in Testing Data :')\n",
    "print ('Positive Sentiment ', str(sum(y_test == 1)/ len(y_test) * 100.0))\n",
    "print ('Negative Sentiment ', str(sum(y_test == 0)/ len(y_test) * 100.0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3883c4e6-5628-4811-8222-b50b2e55aa51",
   "metadata": {},
   "source": [
    "### Model Testing\n",
    "Use TF-IDF vectorizer to transform text into vector based on the frequency of word in the text. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0803a5db-c674-45f5-aca2-9b50b466abde",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "clf = MultinomialNB()\n",
    "\n",
    "pipe = Pipeline([(\"tfidf\", tfidf), (\"clf\", clf)])\n",
    "\n",
    "param_grid = {\n",
    "    'tfidf__ngram_range':[(1,1), (1,2), (1,3)],\n",
    "    'tfidf__min_df':[1, 2, 5, 10, 20],\n",
    "    'clf__fit_prior':[False, True]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c993a49f-5766-4312-a72d-5dcaf117959d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rs = RandomizedSearchCV(estimator = pipe, param_distributions = param_grid, verbose = 2, n_jobs = -1)\n",
    "rs.fit(X_train['spacy_text'], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec48043-0d29-460b-8f3a-f08b4b35cfa3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred = rs.predict(X_test['spacy_text'])\n",
    "\n",
    "print(f'Accuracy: {accuracy_score(y_test, y_pred)}')\n",
    "print(f'ROC-AUC Score: {roc_auc_score(y_test, y_pred)}')\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19778ff-0d0c-4f66-b573-a251b0eb71ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the best parameters \n",
    "print(rs.best_params_)\n",
    "print(rs.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa6abe1-983a-4f26-96b8-0d960184d850",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_prob = rs.predict_proba(X_test['spacy_text'])\n",
    "positive_class_prob = sentiment_prob[:, 1]\n",
    "\n",
    "# Calculate ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, positive_class_prob, pos_label=1)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Randomized Search Cross Validation ROC Curve')\n",
    "plt.show()\n",
    "\n",
    "print(roc_auc_score(y_test, positive_class_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21bd5f07-fd4c-49dc-a404-e30f2faa3254",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(min_df = 10, ngram_range = (1,2))\n",
    "\n",
    "X_train_tf = tfidf.fit_transform(X_train['spacy_text'])\n",
    "X_test_tf = tfidf.transform(X_test['spacy_text'])\n",
    "\n",
    "linear = LinearSVC(random_state = 42, tol = 1e-5)\n",
    "linear.fit(X_train_tf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd6dfe9-da5c-4585-84f6-92104737f72f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred = linear.predict(X_test_tf)\n",
    "print ('Accuracy Score:', accuracy_score(y_test, y_pred))\n",
    "print ('ROC-AUC Score:', roc_auc_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34448df9-4922-467e-8c9d-33399232e2c2",
   "metadata": {},
   "source": [
    "### Sample Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c37698-e099-430a-90f5-120f0d959b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_reviews = cleaned_text.sample(5)\n",
    "sample_reviews_tf = tfidf.transform(sample_reviews['spacy_text'])\n",
    "sentiment_predictions = linear.predict(sample_reviews_tf)\n",
    "sentiment_predictions = pd.DataFrame(data = sentiment_predictions,\n",
    "                                     index=sample_reviews.index,\n",
    "                                     columns=['sentiment_prediction'])\n",
    "sample_reviews = pd.concat([sample_reviews, sentiment_predictions], axis=1)\n",
    "print ('Some sample reviews with their sentiment - ')\n",
    "sample_reviews[['text', 'spacy_text','rating', 'sentiment_prediction']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f0c7be-e982-49d8-85bf-b3b81bca4a46",
   "metadata": {},
   "source": [
    "## Topic Modeling\n",
    "\n",
    "Unsupervised learning NLP technique to find the underlying topics in a collection of text documents. \n",
    "\n",
    "Singular Value Decomposition (SVD, aka Latent Semantic Indexing)\n",
    "\n",
    "Non-Negative Matrix Factorization (NMF) yields two matrices: W and H. Matrix W (document-topic matrix) shows the distribution of the topics across the documents. Matrix H (term-topic matrix) captures the term significance across the topics. \n",
    "- Easier to interpret since elements in matrices is positive\n",
    "- Higher score means stronger relevance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80657ffa-aa00-4a73-8694-ad227498be90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that displays the top 10 words in the topics\n",
    "def display_topics(model, features, no_top_words = 5):\n",
    "    for topic, word_vector in enumerate(model.components_):\n",
    "        total = word_vector.sum()\n",
    "        largest = word_vector.argsort()[::-1] # invert sort order \n",
    "        print(f\"\\nTopic {topic:02d}\") ## Topic number \n",
    "        for i in range(0, no_top_words): \n",
    "            print(f\"    {features[largest[i]]} ({word_vector[largest[i]] * 100.0 / total:.2f})\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c728d1f4-28b8-4a00-9ac4-ddedfd111eff",
   "metadata": {},
   "source": [
    "### SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23936663-eee4-44aa-9cad-d8bd2a2c4251",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "svd_pipe = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('svd', TruncatedSVD(n_components = 7))\n",
    "])\n",
    "\n",
    "svd_pipe.fit(cleaned_text['spacy_text'])\n",
    "vocab = svd_pipe.named_steps['tfidf'].get_feature_names_out()\n",
    "components = svd_pipe.named_steps['svd'].components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41416e8b-fac9-4cad-bc5b-d466bde0a4bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "topic_num = 0\n",
    "\n",
    "pd.DataFrame({\n",
    "    'word': vocab,\n",
    "    'weight': components[topic_num]\n",
    "}).sort_values('weight', ascending = False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7caf581-528e-4184-ba89-baaa21a62417",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "display_topics(svd_pipe.named_steps['svd'], vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cfde545-2255-4d79-9cec-8a2c5861d1e9",
   "metadata": {},
   "source": [
    "### NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ba586b-ed24-4ffc-960c-23ce3b28ddcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf_pipe = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('nmf', NMF(n_components = 7))\n",
    "])\n",
    "\n",
    "nmf_pipe.fit(cleaned_text['spacy_text'])\n",
    "\n",
    "nmf_vocab = nmf_pipe.named_steps['tfidf'].get_feature_names_out()\n",
    "nmf_components = nmf_pipe.named_steps['nmf'].components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521a4b92-ee80-47f5-9925-069ea5f31501",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "topic_num = 0\n",
    "\n",
    "pd.DataFrame({\n",
    "    'word': vocab,\n",
    "    'weight': components[topic_num]\n",
    "}).sort_values('weight', ascending = False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd46f78-fcde-4cc4-a5ac-c085acb368ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "display_topics(nmf_pipe.named_steps['nmf'], vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5826ae-2684-4d96-bbbf-53d6349f30c9",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7969902-aeb1-4b1b-a43c-8a39e1d46284",
   "metadata": {},
   "source": [
    "### How many reviews are there per year?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfbb1d31-9ec0-4cca-acca-c2f6b47fa55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Displays graphs directly within the notebook\n",
    "%matplotlib inline \n",
    "\n",
    "# Create a year column from the timestamp column \n",
    "cleaned_text['year'] = cleaned_text['timestamp'].dt.year\n",
    "\n",
    "# Group by year and count reviews \n",
    "reviews_per_year = cleaned_text.groupby('year').size()\n",
    "\n",
    "# Plot \n",
    "reviews_per_year.plot(kind = 'bar', figsize = (4,4), color = 'skyblue')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
