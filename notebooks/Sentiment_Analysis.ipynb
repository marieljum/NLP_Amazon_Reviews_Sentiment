{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf79bba4-138d-4937-810a-99ac2354ed4c",
   "metadata": {},
   "source": [
    "# Sentiment Analysis Using Various Approaches\n",
    "\n",
    "## Lexicon-based approach \n",
    "- Unsupervised learning\n",
    "- Based on calculating sentiment scores of words in a document from lexicons.\n",
    "- Each word's sentiment is determined, and the scores are combined to calculate the overall sentiment of the sentence. \n",
    "- A lexicon is a dictionary that contains a collection of words that is categorized as positive, negative, and neutral by experts. Their scores can change over time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c66c1d2d-5190-4a5b-a4dd-08e620fd81f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import json\n",
    "import time\n",
    "import re\n",
    "\n",
    "# Text cleaning\n",
    "from nltk import sent_tokenize, word_tokenize, regexp_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# NLTK Bing Liu Lexicon \n",
    "import nltk\n",
    "# nltk.download('opinion_lexicon')\n",
    "from nltk.corpus import opinion_lexicon\n",
    "from nltk.tokenize import word_tokenize \n",
    "\n",
    "# VADER \n",
    "import nltk.corpus\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad46dc4d-99a0-42a2-86e1-2be2a26e242b",
   "metadata": {},
   "source": [
    "## Loading a subset of reviews and meta data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30beeb6b-563d-4b90-aeed-7ad12b45e2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1 \n",
    "total_rows = 0\n",
    "\n",
    "def process_chunks(file, chunksize = 1000):\n",
    "\n",
    "    # Setting as global variables\n",
    "    global n, total_rows  \n",
    "    \n",
    "    chunks = pd.read_json(file, lines=True, chunksize = chunksize)\n",
    "    dfs = []  \n",
    "    n_chunks = 0\n",
    "\n",
    "    for chunk in chunks:\n",
    "        dfs.append(chunk)\n",
    "        n_chunks += 1  # Count the number of chunks processed\n",
    "        print(len(chunk), \" rows added\")\n",
    "        n += 1 \n",
    "        total_rows += len(chunk)\n",
    "        if n_chunks >= 10:  # Process only the first 5 chunks\n",
    "            break  \n",
    "            \n",
    "    print(\"Done\")\n",
    "    print(\"Total rows:\", total_rows)\n",
    "    return pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68a6d07d-3148-430b-be2f-6889f87b8375",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000  rows added\n",
      "1000  rows added\n",
      "1000  rows added\n",
      "1000  rows added\n",
      "1000  rows added\n",
      "1000  rows added\n",
      "1000  rows added\n",
      "1000  rows added\n",
      "1000  rows added\n",
      "1000  rows added\n",
      "Done\n",
      "Total rows: 10000\n",
      "Created a subset of the reviews dataset\n",
      "Execution time: 0.390625 seconds\n",
      "--------------\n",
      "1000  rows added\n",
      "1000  rows added\n",
      "1000  rows added\n",
      "1000  rows added\n",
      "1000  rows added\n",
      "1000  rows added\n",
      "1000  rows added\n",
      "1000  rows added\n",
      "1000  rows added\n",
      "1000  rows added\n",
      "Done\n",
      "Total rows: 20000\n",
      "Created a subset of the meta dataset\n",
      "Execution time: 1.359375 seconds\n"
     ]
    }
   ],
   "source": [
    "reviews = \"../data/Home_and_Kitchen.jsonl\"\n",
    "meta = \"../data/meta_Home_and_Kitchen.jsonl\"\n",
    "\n",
    "start = time.process_time()\n",
    "\n",
    "reviews_subset = process_chunks(reviews)\n",
    "\n",
    "end = time.process_time()\n",
    "elapsed_time = end - start\n",
    "print('Created a subset of the reviews dataset')\n",
    "print('Execution time:', elapsed_time, 'seconds')\n",
    "\n",
    "print('--------------')\n",
    "start = time.process_time()\n",
    "\n",
    "meta_subset = process_chunks(meta)\n",
    "\n",
    "end = time.process_time()\n",
    "elapsed_time = end - start\n",
    "print('Created a subset of the meta dataset')\n",
    "print('Execution time:', elapsed_time, 'seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54459d30-0e0f-4b8b-be54-26d88bec01eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>images</th>\n",
       "      <th>asin</th>\n",
       "      <th>parent_asin</th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>helpful_vote</th>\n",
       "      <th>verified_purchase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Received Used &amp; scratched item! Purchased new!</td>\n",
       "      <td>Livid.  Once again received an obviously used ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>B007WQ9YNO</td>\n",
       "      <td>B09XWYG6X1</td>\n",
       "      <td>AFKZENTNBQ7A7V7UXW5JJI6UGRYQ</td>\n",
       "      <td>2023-02-26 01:03:29.298</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Excellent for moving &amp; storage &amp; floods!</td>\n",
       "      <td>I purchased these for multiple reasons. The ma...</td>\n",
       "      <td>[]</td>\n",
       "      <td>B09H2VJW6K</td>\n",
       "      <td>B0BXDLF8TW</td>\n",
       "      <td>AFKZENTNBQ7A7V7UXW5JJI6UGRYQ</td>\n",
       "      <td>2022-12-26 08:30:10.846</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Lid very loose- needs a gasket imo. Small base.</td>\n",
       "      <td>[[VIDEOID:c87e962bc893a948856b0f1b285ce6cc]] I...</td>\n",
       "      <td>[{'small_image_url': 'https://m.media-amazon.c...</td>\n",
       "      <td>B07RL297VR</td>\n",
       "      <td>B09G2PW8ZG</td>\n",
       "      <td>AFKZENTNBQ7A7V7UXW5JJI6UGRYQ</td>\n",
       "      <td>2022-05-25 02:54:56.788</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rating                                            title  \\\n",
       "0       1   Received Used & scratched item! Purchased new!   \n",
       "1       5         Excellent for moving & storage & floods!   \n",
       "2       2  Lid very loose- needs a gasket imo. Small base.   \n",
       "\n",
       "                                                text  \\\n",
       "0  Livid.  Once again received an obviously used ...   \n",
       "1  I purchased these for multiple reasons. The ma...   \n",
       "2  [[VIDEOID:c87e962bc893a948856b0f1b285ce6cc]] I...   \n",
       "\n",
       "                                              images        asin parent_asin  \\\n",
       "0                                                 []  B007WQ9YNO  B09XWYG6X1   \n",
       "1                                                 []  B09H2VJW6K  B0BXDLF8TW   \n",
       "2  [{'small_image_url': 'https://m.media-amazon.c...  B07RL297VR  B09G2PW8ZG   \n",
       "\n",
       "                        user_id               timestamp  helpful_vote  \\\n",
       "0  AFKZENTNBQ7A7V7UXW5JJI6UGRYQ 2023-02-26 01:03:29.298             1   \n",
       "1  AFKZENTNBQ7A7V7UXW5JJI6UGRYQ 2022-12-26 08:30:10.846             0   \n",
       "2  AFKZENTNBQ7A7V7UXW5JJI6UGRYQ 2022-05-25 02:54:56.788             0   \n",
       "\n",
       "   verified_purchase  \n",
       "0               True  \n",
       "1               True  \n",
       "2               True  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_subset.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72cc77c3-d099-4286-9ad9-a0ac30021156",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['rating', 'title', 'text', 'images', 'asin', 'parent_asin', 'user_id',\n",
       "       'timestamp', 'helpful_vote', 'verified_purchase'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_subset.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4824a8-b9ea-43cf-a93c-e2d2f9bac0bc",
   "metadata": {},
   "source": [
    "## Text Cleaning - spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cbe84fe7-0d46-4104-a006-173d7681d4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy \n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4409d870-e176-4674-8a86-7a60bc28fc22",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = spacy.lang.en.stop_words.STOP_WORDS\n",
    "\n",
    "# Update stopwords\n",
    "include_stopwords = {'would', 'I', 'not'}\n",
    "exclude_stopwords = {'i', 'well'}\n",
    "\n",
    "stop_words |= include_stopwords\n",
    "stop_words -= exclude_stopwords\n",
    "\n",
    "def clean_data(doc):\n",
    "    doc = doc.lower()\n",
    "    doc = nlp(doc)\n",
    "    # Lemmatize words \n",
    "    lemmas = [token.lemma_ for token in doc]\n",
    "    # Removing non-alphabetic characters and stopwords\n",
    "    tokens = [lemma for lemma in lemmas if lemma.isalpha() and lemma not in stop_words]\n",
    "    cleaned_doc = \" \".join(tokens)\n",
    "    \n",
    "    return cleaned_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "169b72af-febd-48f2-8c59-23b6a54c754c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\"'d\",\n",
       " \"'ll\",\n",
       " \"'m\",\n",
       " \"'re\",\n",
       " \"'s\",\n",
       " \"'ve\",\n",
       " 'I',\n",
       " 'a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'across',\n",
       " 'after',\n",
       " 'afterwards',\n",
       " 'again',\n",
       " 'against',\n",
       " 'all',\n",
       " 'almost',\n",
       " 'alone',\n",
       " 'along',\n",
       " 'already',\n",
       " 'also',\n",
       " 'although',\n",
       " 'always',\n",
       " 'am',\n",
       " 'among',\n",
       " 'amongst',\n",
       " 'amount',\n",
       " 'an',\n",
       " 'and',\n",
       " 'another',\n",
       " 'any',\n",
       " 'anyhow',\n",
       " 'anyone',\n",
       " 'anything',\n",
       " 'anyway',\n",
       " 'anywhere',\n",
       " 'are',\n",
       " 'around',\n",
       " 'as',\n",
       " 'at',\n",
       " 'back',\n",
       " 'be',\n",
       " 'became',\n",
       " 'because',\n",
       " 'become',\n",
       " 'becomes',\n",
       " 'becoming',\n",
       " 'been',\n",
       " 'before',\n",
       " 'beforehand',\n",
       " 'behind',\n",
       " 'being',\n",
       " 'below',\n",
       " 'beside',\n",
       " 'besides',\n",
       " 'between',\n",
       " 'beyond',\n",
       " 'both',\n",
       " 'bottom',\n",
       " 'but',\n",
       " 'by',\n",
       " 'ca',\n",
       " 'call',\n",
       " 'can',\n",
       " 'cannot',\n",
       " 'could',\n",
       " 'did',\n",
       " 'do',\n",
       " 'does',\n",
       " 'doing',\n",
       " 'done',\n",
       " 'down',\n",
       " 'due',\n",
       " 'during',\n",
       " 'each',\n",
       " 'eight',\n",
       " 'either',\n",
       " 'eleven',\n",
       " 'else',\n",
       " 'elsewhere',\n",
       " 'empty',\n",
       " 'enough',\n",
       " 'even',\n",
       " 'ever',\n",
       " 'every',\n",
       " 'everyone',\n",
       " 'everything',\n",
       " 'everywhere',\n",
       " 'except',\n",
       " 'few',\n",
       " 'fifteen',\n",
       " 'fifty',\n",
       " 'first',\n",
       " 'five',\n",
       " 'for',\n",
       " 'former',\n",
       " 'formerly',\n",
       " 'forty',\n",
       " 'four',\n",
       " 'from',\n",
       " 'front',\n",
       " 'full',\n",
       " 'further',\n",
       " 'get',\n",
       " 'give',\n",
       " 'go',\n",
       " 'had',\n",
       " 'has',\n",
       " 'have',\n",
       " 'he',\n",
       " 'hence',\n",
       " 'her',\n",
       " 'here',\n",
       " 'hereafter',\n",
       " 'hereby',\n",
       " 'herein',\n",
       " 'hereupon',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'however',\n",
       " 'hundred',\n",
       " 'if',\n",
       " 'in',\n",
       " 'indeed',\n",
       " 'into',\n",
       " 'is',\n",
       " 'it',\n",
       " 'its',\n",
       " 'itself',\n",
       " 'just',\n",
       " 'keep',\n",
       " 'last',\n",
       " 'latter',\n",
       " 'latterly',\n",
       " 'least',\n",
       " 'less',\n",
       " 'made',\n",
       " 'make',\n",
       " 'many',\n",
       " 'may',\n",
       " 'me',\n",
       " 'meanwhile',\n",
       " 'might',\n",
       " 'mine',\n",
       " 'more',\n",
       " 'moreover',\n",
       " 'most',\n",
       " 'mostly',\n",
       " 'move',\n",
       " 'much',\n",
       " 'must',\n",
       " 'my',\n",
       " 'myself',\n",
       " \"n't\",\n",
       " 'name',\n",
       " 'namely',\n",
       " 'neither',\n",
       " 'never',\n",
       " 'nevertheless',\n",
       " 'next',\n",
       " 'nine',\n",
       " 'no',\n",
       " 'nobody',\n",
       " 'none',\n",
       " 'noone',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'nothing',\n",
       " 'now',\n",
       " 'nowhere',\n",
       " 'n‘t',\n",
       " 'n’t',\n",
       " 'of',\n",
       " 'off',\n",
       " 'often',\n",
       " 'on',\n",
       " 'once',\n",
       " 'one',\n",
       " 'only',\n",
       " 'onto',\n",
       " 'or',\n",
       " 'other',\n",
       " 'others',\n",
       " 'otherwise',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 'part',\n",
       " 'per',\n",
       " 'perhaps',\n",
       " 'please',\n",
       " 'put',\n",
       " 'quite',\n",
       " 'rather',\n",
       " 're',\n",
       " 'really',\n",
       " 'regarding',\n",
       " 'same',\n",
       " 'say',\n",
       " 'see',\n",
       " 'seem',\n",
       " 'seemed',\n",
       " 'seeming',\n",
       " 'seems',\n",
       " 'serious',\n",
       " 'several',\n",
       " 'she',\n",
       " 'should',\n",
       " 'show',\n",
       " 'side',\n",
       " 'since',\n",
       " 'six',\n",
       " 'sixty',\n",
       " 'so',\n",
       " 'some',\n",
       " 'somehow',\n",
       " 'someone',\n",
       " 'something',\n",
       " 'sometime',\n",
       " 'sometimes',\n",
       " 'somewhere',\n",
       " 'still',\n",
       " 'such',\n",
       " 'take',\n",
       " 'ten',\n",
       " 'than',\n",
       " 'that',\n",
       " 'the',\n",
       " 'their',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'thence',\n",
       " 'there',\n",
       " 'thereafter',\n",
       " 'thereby',\n",
       " 'therefore',\n",
       " 'therein',\n",
       " 'thereupon',\n",
       " 'these',\n",
       " 'they',\n",
       " 'third',\n",
       " 'this',\n",
       " 'those',\n",
       " 'though',\n",
       " 'three',\n",
       " 'through',\n",
       " 'throughout',\n",
       " 'thru',\n",
       " 'thus',\n",
       " 'to',\n",
       " 'together',\n",
       " 'too',\n",
       " 'top',\n",
       " 'toward',\n",
       " 'towards',\n",
       " 'twelve',\n",
       " 'twenty',\n",
       " 'two',\n",
       " 'under',\n",
       " 'unless',\n",
       " 'until',\n",
       " 'up',\n",
       " 'upon',\n",
       " 'us',\n",
       " 'used',\n",
       " 'using',\n",
       " 'various',\n",
       " 'very',\n",
       " 'via',\n",
       " 'was',\n",
       " 'we',\n",
       " 'were',\n",
       " 'what',\n",
       " 'whatever',\n",
       " 'when',\n",
       " 'whence',\n",
       " 'whenever',\n",
       " 'where',\n",
       " 'whereafter',\n",
       " 'whereas',\n",
       " 'whereby',\n",
       " 'wherein',\n",
       " 'whereupon',\n",
       " 'wherever',\n",
       " 'whether',\n",
       " 'which',\n",
       " 'while',\n",
       " 'whither',\n",
       " 'who',\n",
       " 'whoever',\n",
       " 'whole',\n",
       " 'whom',\n",
       " 'whose',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'within',\n",
       " 'without',\n",
       " 'would',\n",
       " 'yet',\n",
       " 'you',\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " '‘d',\n",
       " '‘ll',\n",
       " '‘m',\n",
       " '‘re',\n",
       " '‘s',\n",
       " '‘ve',\n",
       " '’d',\n",
       " '’ll',\n",
       " '’m',\n",
       " '’re',\n",
       " '’s',\n",
       " '’ve'}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0e106305-aa14-4e9b-a426-b7bbd2f03874",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "stop__words = set(stopwords.words('english'))\n",
    "\n",
    "# Update stopwords\n",
    "include_stopwords = {'would', 'I', 'not'}\n",
    "exclude_stopwords = {'i'}\n",
    "\n",
    "stop__words |= include_stopwords\n",
    "stop__words -= exclude_stopwords\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()  # Lowercase text\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)  # Remove punctuation and numbers\n",
    "    tokens = text.split()  # Create tokens \n",
    "    clean_tokens = [lemmatizer.lemmatize(t) for t in tokens if t not in stop__words]  # Lemmatize and remove stop words\n",
    "    clean_text = \" \".join(clean_tokens)  # Join clean tokens\n",
    "    clean_text = \" \".join(clean_text.split())  # Remove extra spaces, tabs, and new lines\n",
    "    \n",
    "    return clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c7b3852c-da9d-42e1-a55f-d08264e3f1c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'I',\n",
       " 'a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'if',\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'would',\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'y',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves'}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop__words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6891812e-5019-4326-8815-2fdc98966844",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_text = reviews_subset.copy()\n",
    "cleaned_text['spacy_text'] = cleaned_text['text'].apply(clean_data)\n",
    "cleaned_text['nltk_text'] = cleaned_text['text'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "718496cc-0619-4be2-aa5b-e557454c309b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>images</th>\n",
       "      <th>asin</th>\n",
       "      <th>parent_asin</th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>helpful_vote</th>\n",
       "      <th>verified_purchase</th>\n",
       "      <th>spacy_text</th>\n",
       "      <th>nltk_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Received Used &amp; scratched item! Purchased new!</td>\n",
       "      <td>Livid.  Once again received an obviously used ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>B007WQ9YNO</td>\n",
       "      <td>B09XWYG6X1</td>\n",
       "      <td>AFKZENTNBQ7A7V7UXW5JJI6UGRYQ</td>\n",
       "      <td>2023-02-26 01:03:29.298</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>livid receive obviously use item food scratch ...</td>\n",
       "      <td>livid received obviously used item food scratc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Excellent for moving &amp; storage &amp; floods!</td>\n",
       "      <td>I purchased these for multiple reasons. The ma...</td>\n",
       "      <td>[]</td>\n",
       "      <td>B09H2VJW6K</td>\n",
       "      <td>B0BXDLF8TW</td>\n",
       "      <td>AFKZENTNBQ7A7V7UXW5JJI6UGRYQ</td>\n",
       "      <td>2022-12-26 08:30:10.846</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>purchase multiple reason main reason bc apt fl...</td>\n",
       "      <td>i purchased multiple reason main reason i movi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Lid very loose- needs a gasket imo. Small base.</td>\n",
       "      <td>[[VIDEOID:c87e962bc893a948856b0f1b285ce6cc]] I...</td>\n",
       "      <td>[{'small_image_url': 'https://m.media-amazon.c...</td>\n",
       "      <td>B07RL297VR</td>\n",
       "      <td>B09G2PW8ZG</td>\n",
       "      <td>AFKZENTNBQ7A7V7UXW5JJI6UGRYQ</td>\n",
       "      <td>2022-05-25 02:54:56.788</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>videoid want love bc previously buy matching t...</td>\n",
       "      <td>videoidcebcabfbcecc i wanted love bc i previou...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rating                                            title  \\\n",
       "0       1   Received Used & scratched item! Purchased new!   \n",
       "1       5         Excellent for moving & storage & floods!   \n",
       "2       2  Lid very loose- needs a gasket imo. Small base.   \n",
       "\n",
       "                                                text  \\\n",
       "0  Livid.  Once again received an obviously used ...   \n",
       "1  I purchased these for multiple reasons. The ma...   \n",
       "2  [[VIDEOID:c87e962bc893a948856b0f1b285ce6cc]] I...   \n",
       "\n",
       "                                              images        asin parent_asin  \\\n",
       "0                                                 []  B007WQ9YNO  B09XWYG6X1   \n",
       "1                                                 []  B09H2VJW6K  B0BXDLF8TW   \n",
       "2  [{'small_image_url': 'https://m.media-amazon.c...  B07RL297VR  B09G2PW8ZG   \n",
       "\n",
       "                        user_id               timestamp  helpful_vote  \\\n",
       "0  AFKZENTNBQ7A7V7UXW5JJI6UGRYQ 2023-02-26 01:03:29.298             1   \n",
       "1  AFKZENTNBQ7A7V7UXW5JJI6UGRYQ 2022-12-26 08:30:10.846             0   \n",
       "2  AFKZENTNBQ7A7V7UXW5JJI6UGRYQ 2022-05-25 02:54:56.788             0   \n",
       "\n",
       "   verified_purchase                                         spacy_text  \\\n",
       "0               True  livid receive obviously use item food scratch ...   \n",
       "1               True  purchase multiple reason main reason bc apt fl...   \n",
       "2               True  videoid want love bc previously buy matching t...   \n",
       "\n",
       "                                           nltk_text  \n",
       "0  livid received obviously used item food scratc...  \n",
       "1  i purchased multiple reason main reason i movi...  \n",
       "2  videoidcebcabfbcecc i wanted love bc i previou...  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_text.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a4d30c-c991-4605-be1f-c9b401061210",
   "metadata": {},
   "source": [
    "## Bing Liu Lexicon\n",
    "\n",
    "The Bing Liu lexicon has a total of 6, 786 words with 2,005 classified as positive and 4,781 as negative. CLassification is binary (positive or negative)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b5887a47-ad06-4241-b7ce-5fa7f40bd806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of words in opinion lexicon 6789\n",
      "Examples of positive words: ['a+', 'abound', 'abounds', 'abundance', 'abundant', 'accessable', 'accessible', 'acclaim', 'acclaimed', 'acclamation']\n",
      "Examples of negative words: ['2-faced', '2-faces', 'abnormal', 'abolish', 'abominable', 'abominably', 'abominate', 'abomination', 'abort', 'aborted']\n"
     ]
    }
   ],
   "source": [
    "print('Total number of words in opinion lexicon', len(opinion_lexicon.words()))\n",
    "print('Examples of positive words:', opinion_lexicon.positive()[:10])\n",
    "print('Examples of negative words:', opinion_lexicon.negative()[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "41e75ef3-dbe2-493f-86a5-91a5a010d001",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_score = 1\n",
    "neg_score = -1\n",
    "word_dict = {}\n",
    "\n",
    "# Adding the positive words to the dictionary\n",
    "for word in opinion_lexicon.positive():\n",
    "    word_dict[word] = pos_score \n",
    "\n",
    "# Adding the negative words to the dictionary \n",
    "for word in opinion_lexicon.negative():\n",
    "    word_dict[word] = neg_score \n",
    "\n",
    "def bing_liu_score(text):\n",
    "    sentiment_score = 0 \n",
    "    bag_of_words = word_tokenize(text.lower())\n",
    "\n",
    "    # Check if bag_of_words is empty\n",
    "    if bag_of_words: \n",
    "        for word in bag_of_words: \n",
    "            if word in word_dict: \n",
    "                sentiment_score += word_dict[word]\n",
    "        return sentiment_score / len(bag_of_words)\n",
    "    else: \n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "91a39dd6-e6a5-4996-9102-8a7131a4cc02",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>images</th>\n",
       "      <th>asin</th>\n",
       "      <th>parent_asin</th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>helpful_vote</th>\n",
       "      <th>verified_purchase</th>\n",
       "      <th>spacy_text</th>\n",
       "      <th>nltk_text</th>\n",
       "      <th>Bing_Liu_score</th>\n",
       "      <th>Bing_Liu_spaCy</th>\n",
       "      <th>Bing_Liu_nltk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Received Used &amp; scratched item! Purchased new!</td>\n",
       "      <td>Livid.  Once again received an obviously used ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>B007WQ9YNO</td>\n",
       "      <td>B09XWYG6X1</td>\n",
       "      <td>AFKZENTNBQ7A7V7UXW5JJI6UGRYQ</td>\n",
       "      <td>2023-02-26 01:03:29.298</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>livid receive obviously use item food scratch ...</td>\n",
       "      <td>livid received obviously used item food scratc...</td>\n",
       "      <td>-0.085714</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>-0.187500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Excellent for moving &amp; storage &amp; floods!</td>\n",
       "      <td>I purchased these for multiple reasons. The ma...</td>\n",
       "      <td>[]</td>\n",
       "      <td>B09H2VJW6K</td>\n",
       "      <td>B0BXDLF8TW</td>\n",
       "      <td>AFKZENTNBQ7A7V7UXW5JJI6UGRYQ</td>\n",
       "      <td>2022-12-26 08:30:10.846</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>purchase multiple reason main reason bc apt fl...</td>\n",
       "      <td>i purchased multiple reason main reason i movi...</td>\n",
       "      <td>-0.006568</td>\n",
       "      <td>-0.027650</td>\n",
       "      <td>-0.019868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Lid very loose- needs a gasket imo. Small base.</td>\n",
       "      <td>[[VIDEOID:c87e962bc893a948856b0f1b285ce6cc]] I...</td>\n",
       "      <td>[{'small_image_url': 'https://m.media-amazon.c...</td>\n",
       "      <td>B07RL297VR</td>\n",
       "      <td>B09G2PW8ZG</td>\n",
       "      <td>AFKZENTNBQ7A7V7UXW5JJI6UGRYQ</td>\n",
       "      <td>2022-05-25 02:54:56.788</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>videoid want love bc previously buy matching t...</td>\n",
       "      <td>videoidcebcabfbcecc i wanted love bc i previou...</td>\n",
       "      <td>-0.008287</td>\n",
       "      <td>-0.031496</td>\n",
       "      <td>-0.016949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Best purchase ever!</td>\n",
       "      <td>If you live at a higher elevation like me (5k ...</td>\n",
       "      <td>[{'small_image_url': 'https://m.media-amazon.c...</td>\n",
       "      <td>B09CQF4SWV</td>\n",
       "      <td>B08CSZDXZY</td>\n",
       "      <td>AFKZENTNBQ7A7V7UXW5JJI6UGRYQ</td>\n",
       "      <td>2022-05-06 16:38:16.178</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>live high elevation like colorado know buzzer ...</td>\n",
       "      <td>live higher elevation like k colorado know buz...</td>\n",
       "      <td>0.006316</td>\n",
       "      <td>-0.044304</td>\n",
       "      <td>0.009615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Excellent for yarn!</td>\n",
       "      <td>I use these to store yarn. They easily hold 12...</td>\n",
       "      <td>[{'small_image_url': 'https://images-na.ssl-im...</td>\n",
       "      <td>B003U6A3EY</td>\n",
       "      <td>B0C6V27S6N</td>\n",
       "      <td>AFKZENTNBQ7A7V7UXW5JJI6UGRYQ</td>\n",
       "      <td>2020-05-20 00:28:45.940</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>use store yarn easily hold ounce bernat pipsqu...</td>\n",
       "      <td>i use store yarn easily hold ounce bernat pips...</td>\n",
       "      <td>0.035294</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.075000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rating                                            title  \\\n",
       "0       1   Received Used & scratched item! Purchased new!   \n",
       "1       5         Excellent for moving & storage & floods!   \n",
       "2       2  Lid very loose- needs a gasket imo. Small base.   \n",
       "3       5                              Best purchase ever!   \n",
       "4       5                              Excellent for yarn!   \n",
       "\n",
       "                                                text  \\\n",
       "0  Livid.  Once again received an obviously used ...   \n",
       "1  I purchased these for multiple reasons. The ma...   \n",
       "2  [[VIDEOID:c87e962bc893a948856b0f1b285ce6cc]] I...   \n",
       "3  If you live at a higher elevation like me (5k ...   \n",
       "4  I use these to store yarn. They easily hold 12...   \n",
       "\n",
       "                                              images        asin parent_asin  \\\n",
       "0                                                 []  B007WQ9YNO  B09XWYG6X1   \n",
       "1                                                 []  B09H2VJW6K  B0BXDLF8TW   \n",
       "2  [{'small_image_url': 'https://m.media-amazon.c...  B07RL297VR  B09G2PW8ZG   \n",
       "3  [{'small_image_url': 'https://m.media-amazon.c...  B09CQF4SWV  B08CSZDXZY   \n",
       "4  [{'small_image_url': 'https://images-na.ssl-im...  B003U6A3EY  B0C6V27S6N   \n",
       "\n",
       "                        user_id               timestamp  helpful_vote  \\\n",
       "0  AFKZENTNBQ7A7V7UXW5JJI6UGRYQ 2023-02-26 01:03:29.298             1   \n",
       "1  AFKZENTNBQ7A7V7UXW5JJI6UGRYQ 2022-12-26 08:30:10.846             0   \n",
       "2  AFKZENTNBQ7A7V7UXW5JJI6UGRYQ 2022-05-25 02:54:56.788             0   \n",
       "3  AFKZENTNBQ7A7V7UXW5JJI6UGRYQ 2022-05-06 16:38:16.178             0   \n",
       "4  AFKZENTNBQ7A7V7UXW5JJI6UGRYQ 2020-05-20 00:28:45.940             1   \n",
       "\n",
       "   verified_purchase                                         spacy_text  \\\n",
       "0               True  livid receive obviously use item food scratch ...   \n",
       "1               True  purchase multiple reason main reason bc apt fl...   \n",
       "2               True  videoid want love bc previously buy matching t...   \n",
       "3               True  live high elevation like colorado know buzzer ...   \n",
       "4               True  use store yarn easily hold ounce bernat pipsqu...   \n",
       "\n",
       "                                           nltk_text  Bing_Liu_score  \\\n",
       "0  livid received obviously used item food scratc...       -0.085714   \n",
       "1  i purchased multiple reason main reason i movi...       -0.006568   \n",
       "2  videoidcebcabfbcecc i wanted love bc i previou...       -0.008287   \n",
       "3  live higher elevation like k colorado know buz...        0.006316   \n",
       "4  i use store yarn easily hold ounce bernat pips...        0.035294   \n",
       "\n",
       "   Bing_Liu_spaCy  Bing_Liu_nltk  \n",
       "0       -0.200000      -0.187500  \n",
       "1       -0.027650      -0.019868  \n",
       "2       -0.031496      -0.016949  \n",
       "3       -0.044304       0.009615  \n",
       "4        0.062500       0.075000  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_text['Bing_Liu_score'] = cleaned_text['text'].apply(bing_liu_score)\n",
    "cleaned_text['Bing_Liu_spaCy'] = cleaned_text['spacy_text'].apply(bing_liu_score)\n",
    "cleaned_text['Bing_Liu_nltk'] = cleaned_text['nltk_text'].apply(bing_liu_score)\n",
    "cleaned_text.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f9ae872c-f422-45b0-a9bd-7cc4ab196396",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>text</th>\n",
       "      <th>Bing_Liu_score</th>\n",
       "      <th>Bing_Liu_spaCy</th>\n",
       "      <th>Bing_Liu_nltk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>3</td>\n",
       "      <td>It works okay. But I have to tinker with it al...</td>\n",
       "      <td>0.097561</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.181818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5759</th>\n",
       "      <td>5</td>\n",
       "      <td>I ordered this door decoration for my elderly ...</td>\n",
       "      <td>0.051020</td>\n",
       "      <td>0.131579</td>\n",
       "      <td>0.102041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5387</th>\n",
       "      <td>2</td>\n",
       "      <td>These are smaller than teaspoons that come in ...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9167</th>\n",
       "      <td>5</td>\n",
       "      <td>The price was right  I was able to scrape out ...</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2808</th>\n",
       "      <td>3</td>\n",
       "      <td>It's nice for tight spaces but quite flimsy</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      rating                                               text  \\\n",
       "37         3  It works okay. But I have to tinker with it al...   \n",
       "5759       5  I ordered this door decoration for my elderly ...   \n",
       "5387       2  These are smaller than teaspoons that come in ...   \n",
       "9167       5  The price was right  I was able to scrape out ...   \n",
       "2808       3        It's nice for tight spaces but quite flimsy   \n",
       "\n",
       "      Bing_Liu_score  Bing_Liu_spaCy  Bing_Liu_nltk  \n",
       "37          0.097561        0.357143       0.181818  \n",
       "5759        0.051020        0.131579       0.102041  \n",
       "5387        0.000000        0.000000       0.000000  \n",
       "9167        0.058824        0.250000       0.150000  \n",
       "2808        0.000000        0.000000       0.000000  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_text[['rating', 'text', 'Bing_Liu_score', 'Bing_Liu_spaCy', 'Bing_Liu_nltk']].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e23949f0-53f1-4a25-88a5-6115a2ba7668",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>images</th>\n",
       "      <th>asin</th>\n",
       "      <th>parent_asin</th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>helpful_vote</th>\n",
       "      <th>verified_purchase</th>\n",
       "      <th>spacy_text</th>\n",
       "      <th>nltk_text</th>\n",
       "      <th>Bing_Liu_score</th>\n",
       "      <th>Bing_Liu_spaCy</th>\n",
       "      <th>Bing_Liu_nltk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect mattress</td>\n",
       "      <td>OK, we bought this mattress for our guest room...</td>\n",
       "      <td>[]</td>\n",
       "      <td>B0777K9RGX</td>\n",
       "      <td>B0BPBLYF85</td>\n",
       "      <td>AGGZ357AO26RQZVRLGU4D4N52DZQ</td>\n",
       "      <td>2020-01-06 02:16:33.373</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>ok buy mattress guest room wish mattress serio...</td>\n",
       "      <td>ok bought mattress guest room im wishing mattr...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>4</td>\n",
       "      <td>Nice sparkly touch</td>\n",
       "      <td>Nice quality. A little pricey for the amount b...</td>\n",
       "      <td>[]</td>\n",
       "      <td>B01I3Q6BHS</td>\n",
       "      <td>B01I3Q6BHS</td>\n",
       "      <td>AGKASBHYZPGTEPO6LWZPVJWB2BVA</td>\n",
       "      <td>2017-01-30 15:35:05.000</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>nice quality little pricey reusable desire</td>\n",
       "      <td>nice quality little pricey amount also reusabl...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>5</td>\n",
       "      <td>yay</td>\n",
       "      <td>happily loved by our 1 year old.  she makes fu...</td>\n",
       "      <td>[]</td>\n",
       "      <td>B00563XRYM</td>\n",
       "      <td>B00563XRYM</td>\n",
       "      <td>AGCI7FAH4GL5FI65HYLKWTMFZ2CQ</td>\n",
       "      <td>2013-11-20 01:54:13.000</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>happily love year old funny noise think funny ...</td>\n",
       "      <td>happily loved year old make funny noise think ...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>3</td>\n",
       "      <td>I love the colors &amp; systles of the mugs</td>\n",
       "      <td>I love the colors &amp; systles of the mugs, but t...</td>\n",
       "      <td>[]</td>\n",
       "      <td>B004O39RJ4</td>\n",
       "      <td>B004O39RJ4</td>\n",
       "      <td>AGXVBIUFLFGMVLATYXHJYL4A5Q7Q</td>\n",
       "      <td>2015-04-06 13:13:55.000</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>love color systle mug small size anticipate gr...</td>\n",
       "      <td>i love color systles mug smaller size i antici...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>5</td>\n",
       "      <td>It peels garlic</td>\n",
       "      <td>It does the job.</td>\n",
       "      <td>[]</td>\n",
       "      <td>B077MNPF15</td>\n",
       "      <td>B077MNPF15</td>\n",
       "      <td>AGKHLEW2SOWHNMFQIJGBECAF7INQ</td>\n",
       "      <td>2019-07-23 04:28:05.311</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>job</td>\n",
       "      <td>job</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9976</th>\n",
       "      <td>5</td>\n",
       "      <td>Does the job!</td>\n",
       "      <td>Just what I was looking for.</td>\n",
       "      <td>[]</td>\n",
       "      <td>B0765BTD13</td>\n",
       "      <td>B0BWJ277SP</td>\n",
       "      <td>AE57MRF2R2ALCC6H5WQLFKT7KSSA</td>\n",
       "      <td>2021-03-05 15:23:36.385</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>look</td>\n",
       "      <td>i looking</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9979</th>\n",
       "      <td>1</td>\n",
       "      <td>IT INTERFERS WITH THE STEAMER BUTTON</td>\n",
       "      <td>It is lightweight and deep enough to steam ent...</td>\n",
       "      <td>[]</td>\n",
       "      <td>B079CLQJ5Z</td>\n",
       "      <td>B079CLQJ5Z</td>\n",
       "      <td>AE57MRF2R2ALCC6H5WQLFKT7KSSA</td>\n",
       "      <td>2019-10-05 16:57:37.457</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>lightweight deep steam entire head broccoli ca...</td>\n",
       "      <td>lightweight deep enough steam entire head broc...</td>\n",
       "      <td>0.018182</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.034483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9987</th>\n",
       "      <td>1</td>\n",
       "      <td>Not comfortable</td>\n",
       "      <td>Uncomfortable, not cool, and disappointed. Eas...</td>\n",
       "      <td>[]</td>\n",
       "      <td>B07MY34QH7</td>\n",
       "      <td>B0BLXVK6QX</td>\n",
       "      <td>AFPHKIJFGIU4G4POXRFCEF5RJJHA</td>\n",
       "      <td>2020-12-05 16:13:34.579</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>uncomfortable cool disappoint easy return policy</td>\n",
       "      <td>uncomfortable cool disappointed easy return po...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9991</th>\n",
       "      <td>5</td>\n",
       "      <td>Nice cups</td>\n",
       "      <td>Gave as a gift, well received</td>\n",
       "      <td>[]</td>\n",
       "      <td>B079L1Q2KK</td>\n",
       "      <td>B079L1Q2KK</td>\n",
       "      <td>AFPHKIJFGIU4G4POXRFCEF5RJJHA</td>\n",
       "      <td>2020-12-05 15:12:34.299</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>gift receive</td>\n",
       "      <td>gave gift well received</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9993</th>\n",
       "      <td>1</td>\n",
       "      <td>Broken when received</td>\n",
       "      <td>Bottle was broken but return policy was easy</td>\n",
       "      <td>[]</td>\n",
       "      <td>B00A7V9AVC</td>\n",
       "      <td>B07QWLX5FF</td>\n",
       "      <td>AFPHKIJFGIU4G4POXRFCEF5RJJHA</td>\n",
       "      <td>2020-12-05 14:57:32.936</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>bottle break return policy easy</td>\n",
       "      <td>bottle broken return policy easy</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1069 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      rating                                    title  \\\n",
       "15         5                         Perfect mattress   \n",
       "25         4                       Nice sparkly touch   \n",
       "35         5                                      yay   \n",
       "52         3  I love the colors & systles of the mugs   \n",
       "60         5                          It peels garlic   \n",
       "...      ...                                      ...   \n",
       "9976       5                            Does the job!   \n",
       "9979       1     IT INTERFERS WITH THE STEAMER BUTTON   \n",
       "9987       1                          Not comfortable   \n",
       "9991       5                                Nice cups   \n",
       "9993       1                     Broken when received   \n",
       "\n",
       "                                                   text images        asin  \\\n",
       "15    OK, we bought this mattress for our guest room...     []  B0777K9RGX   \n",
       "25    Nice quality. A little pricey for the amount b...     []  B01I3Q6BHS   \n",
       "35    happily loved by our 1 year old.  she makes fu...     []  B00563XRYM   \n",
       "52    I love the colors & systles of the mugs, but t...     []  B004O39RJ4   \n",
       "60                                     It does the job.     []  B077MNPF15   \n",
       "...                                                 ...    ...         ...   \n",
       "9976                       Just what I was looking for.     []  B0765BTD13   \n",
       "9979  It is lightweight and deep enough to steam ent...     []  B079CLQJ5Z   \n",
       "9987  Uncomfortable, not cool, and disappointed. Eas...     []  B07MY34QH7   \n",
       "9991                      Gave as a gift, well received     []  B079L1Q2KK   \n",
       "9993       Bottle was broken but return policy was easy     []  B00A7V9AVC   \n",
       "\n",
       "     parent_asin                       user_id               timestamp  \\\n",
       "15    B0BPBLYF85  AGGZ357AO26RQZVRLGU4D4N52DZQ 2020-01-06 02:16:33.373   \n",
       "25    B01I3Q6BHS  AGKASBHYZPGTEPO6LWZPVJWB2BVA 2017-01-30 15:35:05.000   \n",
       "35    B00563XRYM  AGCI7FAH4GL5FI65HYLKWTMFZ2CQ 2013-11-20 01:54:13.000   \n",
       "52    B004O39RJ4  AGXVBIUFLFGMVLATYXHJYL4A5Q7Q 2015-04-06 13:13:55.000   \n",
       "60    B077MNPF15  AGKHLEW2SOWHNMFQIJGBECAF7INQ 2019-07-23 04:28:05.311   \n",
       "...          ...                           ...                     ...   \n",
       "9976  B0BWJ277SP  AE57MRF2R2ALCC6H5WQLFKT7KSSA 2021-03-05 15:23:36.385   \n",
       "9979  B079CLQJ5Z  AE57MRF2R2ALCC6H5WQLFKT7KSSA 2019-10-05 16:57:37.457   \n",
       "9987  B0BLXVK6QX  AFPHKIJFGIU4G4POXRFCEF5RJJHA 2020-12-05 16:13:34.579   \n",
       "9991  B079L1Q2KK  AFPHKIJFGIU4G4POXRFCEF5RJJHA 2020-12-05 15:12:34.299   \n",
       "9993  B07QWLX5FF  AFPHKIJFGIU4G4POXRFCEF5RJJHA 2020-12-05 14:57:32.936   \n",
       "\n",
       "      helpful_vote  verified_purchase  \\\n",
       "15               0               True   \n",
       "25               0               True   \n",
       "35               0               True   \n",
       "52               0               True   \n",
       "60               0               True   \n",
       "...            ...                ...   \n",
       "9976             0               True   \n",
       "9979             2               True   \n",
       "9987             1               True   \n",
       "9991             0               True   \n",
       "9993             0               True   \n",
       "\n",
       "                                             spacy_text  \\\n",
       "15    ok buy mattress guest room wish mattress serio...   \n",
       "25           nice quality little pricey reusable desire   \n",
       "35    happily love year old funny noise think funny ...   \n",
       "52    love color systle mug small size anticipate gr...   \n",
       "60                                                  job   \n",
       "...                                                 ...   \n",
       "9976                                               look   \n",
       "9979  lightweight deep steam entire head broccoli ca...   \n",
       "9987   uncomfortable cool disappoint easy return policy   \n",
       "9991                                       gift receive   \n",
       "9993                    bottle break return policy easy   \n",
       "\n",
       "                                              nltk_text  Bing_Liu_score  \\\n",
       "15    ok bought mattress guest room im wishing mattr...        0.000000   \n",
       "25    nice quality little pricey amount also reusabl...        0.000000   \n",
       "35    happily loved year old make funny noise think ...        0.000000   \n",
       "52    i love color systles mug smaller size i antici...        0.000000   \n",
       "60                                                  job        0.000000   \n",
       "...                                                 ...             ...   \n",
       "9976                                          i looking        0.000000   \n",
       "9979  lightweight deep enough steam entire head broc...        0.018182   \n",
       "9987  uncomfortable cool disappointed easy return po...        0.000000   \n",
       "9991                            gave gift well received        0.142857   \n",
       "9993                   bottle broken return policy easy        0.000000   \n",
       "\n",
       "      Bing_Liu_spaCy  Bing_Liu_nltk  \n",
       "15               0.0       0.000000  \n",
       "25               0.0       0.000000  \n",
       "35               0.0       0.000000  \n",
       "52               0.0       0.000000  \n",
       "60               0.0       0.000000  \n",
       "...              ...            ...  \n",
       "9976             0.0       0.000000  \n",
       "9979             0.0       0.034483  \n",
       "9987             0.0       0.000000  \n",
       "9991             0.0       0.250000  \n",
       "9993             0.0       0.000000  \n",
       "\n",
       "[1069 rows x 15 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look for scores of zeroes in Bing_Liu_spaCy and Bing_Liu_nltk columns \n",
    "cleaned_text[cleaned_text['Bing_Liu_spaCy'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e3281f8c-b103-4cdc-81e3-8a49fd7eb37a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Best purchase ever!\n",
      "\n",
      "Text: If you live at a higher elevation like me (5k Colorado) just know that after the buzzer beeps you might wanna leave the hard boiled eggs inside the steamed cooker for another minute or two if you want the egg cooked all the way through. I also add a bit more water than the fill line says, but again that’s bc of my elevation & it evaporates quickly.  It’s not any quicker than I used to make them, but it’s a lot less water. I’m disabled & have a TBI rn so the auto-cutoff was a no-brained for me. I bought the blue bc it was cheapest.  My service 🐶  🐶 love hard boiled eggs too so we are enjoying this new addition to our kitchen.  My only regret is that I did not buy it sooner & that Amazon never has the color I want for the cheapest price, but I can live with the bb blue.  We have used it 3x & so far it’s working okay. Oh- don’t place it under upper cabinets as it has a vent hole & it will vent & it will make the cabinets sweat.  Give it some room to breathe imo.  I keep a pair of tongs handy to unload the eggs & dunk them in my ice bath. Yes. You end up using water again, but I have house plants I’ll use it on anyways so it not just wasted water.  If it holds up & doesn’t break down it will truly be one of my top 10 if not top 5 amazon lifetime purchases.  It’s that good.  Nothing is worse than watching eggs boil. Lol.  I start this up at the same time I start my tea brewing and go about feeding the wildlife in my backyard.  It’s just a very peaceful start to my day. I know ppl have said stuff about the buzzer, but honestly I happen to be hearing impaired in both ears & my service dogs are trained to hear for me. I like that it’s loud enough that if my pups are outside & I am in my living room or just outside on my patio with them & my screen door is open then they & often I can still hear it.  I wish appliances had volume options on their alarms, but until then I am very happy with this one.  I am just extremely happy with this purchase. It’s been a long time since I could say that. Lol.\n",
      "\n",
      "Text: live high elevation like colorado know buzzer beep wanna leave hard boil egg inside steam cooker minute want egg cook way add bit water fill line bc elevation evaporate quickly quick use lot water disabled tbi rn auto cutoff brain buy blue bc cheap service love hard boil egg enjoy new addition kitchen regret buy soon amazon color want cheap price live bb blue use far work okay place upper cabinet vent hole vent cabinet sweat room breathe imo pair tong handy unload egg dunk ice bath yes end use water house plant use anyways waste water hold break truly amazon lifetime purchase good bad watch egg boil lol start time start tea brewing feed wildlife backyard peaceful start day know ppl stuff buzzer honestly happen hear impair ear service dog train hear like loud pup outside living room outside patio screen door open hear wish appliance volume option alarm happy extremely happy purchase long time lol\n",
      "\n",
      "Text: live higher elevation like k colorado know buzzer beep might wanna leave hard boiled egg inside steamed cooker another minute two want egg cooked way i also add bit water fill line say thats bc elevation evaporates quickly quicker i used make lot le water im disabled tbi rn autocutoff nobrained i bought blue bc cheapest service love hard boiled egg enjoying new addition kitchen regret i buy sooner amazon never color i want cheapest price i live bb blue used x far working okay oh dont place upper cabinet vent hole vent make cabinet sweat give room breathe imo i keep pair tongs handy unload egg dunk ice bath yes end using water i house plant ill use anyways wasted water hold doesnt break truly one top top amazon lifetime purchase good nothing worse watching egg boil lol i start time i start tea brewing go feeding wildlife backyard peaceful start day i know ppl said stuff buzzer honestly i happen hearing impaired ear service dog trained hear i like loud enough pup outside i living room outside patio screen door open often i still hear i wish appliance volume option alarm i happy one i extremely happy purchase long time since i could say lol\n"
     ]
    }
   ],
   "source": [
    "i = 3\n",
    "print(f'Title: {cleaned_text.loc[i,\"title\"]}\\n')\n",
    "\n",
    "print(f'Text: {cleaned_text.loc[i,\"text\"]}\\n')\n",
    "\n",
    "print(f'Text: {cleaned_text.loc[i,\"spacy_text\"]}\\n')\n",
    "\n",
    "print(f'Text: {cleaned_text.loc[i,\"nltk_text\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fc64278e-05c5-4666-93dd-788f93858bea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   rating  Bing_Liu_score  Bing_Liu_spaCy  Bing_Liu_nltk\n",
      "0       1       -0.031370       -0.074885      -0.051852\n",
      "1       2        0.003011       -0.003263       0.010138\n",
      "2       3        0.031123        0.057409       0.065607\n",
      "3       4        0.066978        0.140987       0.137529\n",
      "4       5        0.129455        0.249908       0.236131\n"
     ]
    }
   ],
   "source": [
    "# Calculate mean sentiment score for each rating category\n",
    "mean_scores = cleaned_text.groupby('rating').agg({\n",
    "    'Bing_Liu_score':'mean',\n",
    "    'Bing_Liu_spaCy': 'mean',\n",
    "    'Bing_Liu_nltk': 'mean'\n",
    "}).reset_index()\n",
    "\n",
    "print(mean_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5cccf5d8-54bb-4da7-afb2-635be4b40c10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   rating  Bing_Liu_score  Bing_Liu_spaCy  Bing_Liu_nltk\n",
      "0       1        0.333333             1.0            1.0\n",
      "1       2        0.250000             1.0            1.0\n",
      "2       3        1.000000             1.0            1.0\n",
      "3       4        1.000000             1.0            1.0\n",
      "4       5        1.000000             1.0            1.0\n"
     ]
    }
   ],
   "source": [
    "# Calculate max sentiment score for each rating category\n",
    "max_scores = cleaned_text.groupby('rating').agg({\n",
    "    'Bing_Liu_score':'max',\n",
    "    'Bing_Liu_spaCy': 'max',\n",
    "    'Bing_Liu_nltk': 'max'\n",
    "}).reset_index()\n",
    "\n",
    "print(max_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "091acff1-2121-41af-9a7d-31b4b61c763c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   rating  Bing_Liu_score  Bing_Liu_spaCy  Bing_Liu_nltk\n",
      "0       1       -1.000000            -1.0      -1.000000\n",
      "1       2       -0.666667            -1.0      -0.666667\n",
      "2       3       -0.500000            -1.0      -0.500000\n",
      "3       4       -1.000000            -1.0      -1.000000\n",
      "4       5       -0.500000            -1.0      -1.000000\n"
     ]
    }
   ],
   "source": [
    "# Calculate min sentiment score for each rating category\n",
    "min_scores = cleaned_text.groupby('rating').agg({\n",
    "    'Bing_Liu_score':'min',\n",
    "    'Bing_Liu_spaCy': 'min',\n",
    "    'Bing_Liu_nltk': 'min'\n",
    "}).reset_index()\n",
    "\n",
    "print(min_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4291b896-3b1b-4c16-bd45-0d7890b08f86",
   "metadata": {},
   "source": [
    "## VADER Lexicon\n",
    "Rule-based lexicon. \n",
    "9,000 features with scales of [-4] Extremely Negative to [4] Extremely Positive with [0] for Neutral or Neither. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e75ea6-5546-46fa-b399-9bb22534db27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
