{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf79bba4-138d-4937-810a-99ac2354ed4c",
   "metadata": {},
   "source": [
    "# Sentiment Analysis Using Various Approaches\n",
    "\n",
    "## Lexicon-based approach \n",
    "- Unsupervised learning\n",
    "- Based on calculating sentiment scores of words in a document from predetermined dictionaries, called lexicons.\n",
    "- Each word's sentiment is determined, and the scores are combined to calculate the overall sentiment of the sentence. \n",
    "- A lexicon is a dictionary that contains a collection of words that is categorized as positive, negative, and neutral by experts. Their scores can change over time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c66c1d2d-5190-4a5b-a4dd-08e620fd81f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package opinion_lexicon to\n",
      "[nltk_data]     C:\\Users\\MJ\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package opinion_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import json\n",
    "import time\n",
    "\n",
    "# NLTK Bing Liu Lexicon \n",
    "import nltk\n",
    "# nltk.download('opinion_lexicon')\n",
    "from nltk.corpus import opinion_lexicon\n",
    "from nltk.tokenize import word_tokenize \n",
    "\n",
    "# VADER \n",
    "import nltk.corpus\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad46dc4d-99a0-42a2-86e1-2be2a26e242b",
   "metadata": {},
   "source": [
    "## Loading a subset of reviews and meta data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30beeb6b-563d-4b90-aeed-7ad12b45e2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1 \n",
    "total_rows = 0\n",
    "\n",
    "def process_chunks(file, chunksize = 10000):\n",
    "\n",
    "    # Setting as global variables\n",
    "    global n, total_rows  \n",
    "    \n",
    "    chunks = pd.read_json(file, lines=True, chunksize = chunksize)\n",
    "    dfs = []  \n",
    "    n_chunks = 0\n",
    "\n",
    "    for chunk in chunks:\n",
    "        dfs.append(chunk)\n",
    "        n_chunks += 1  # Count the number of chunks processed\n",
    "        print(len(chunk), \" rows added\")\n",
    "        n += 1 \n",
    "        total_rows += len(chunk)\n",
    "        if n_chunks >= 10:  # Process only the first 5 chunks\n",
    "            break  \n",
    "            \n",
    "    print(\"Done\")\n",
    "    print(\"Total rows:\", total_rows)\n",
    "    return pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68a6d07d-3148-430b-be2f-6889f87b8375",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000  rows added\n",
      "10000  rows added\n",
      "10000  rows added\n",
      "10000  rows added\n",
      "10000  rows added\n",
      "10000  rows added\n",
      "10000  rows added\n",
      "10000  rows added\n",
      "10000  rows added\n",
      "10000  rows added\n",
      "Done\n",
      "Total rows: 100000\n",
      "Created a subset of the reviews dataset\n",
      "Execution time: 1.84375 seconds\n",
      "--------------\n",
      "10000  rows added\n",
      "10000  rows added\n",
      "10000  rows added\n",
      "10000  rows added\n",
      "10000  rows added\n",
      "10000  rows added\n",
      "10000  rows added\n",
      "10000  rows added\n",
      "10000  rows added\n",
      "10000  rows added\n",
      "Done\n",
      "Total rows: 200000\n",
      "Created a subset of the meta dataset\n",
      "Execution time: 8.3125 seconds\n"
     ]
    }
   ],
   "source": [
    "reviews = \"../data/Home_and_Kitchen.jsonl\"\n",
    "meta = \"../data/meta_Home_and_Kitchen.jsonl\"\n",
    "\n",
    "start = time.process_time()\n",
    "\n",
    "reviews_subset = process_chunks(reviews)\n",
    "\n",
    "end = time.process_time()\n",
    "elapsed_time = end - start\n",
    "print('Created a subset of the reviews dataset')\n",
    "print('Execution time:', elapsed_time, 'seconds')\n",
    "\n",
    "print('--------------')\n",
    "start = time.process_time()\n",
    "\n",
    "meta_subset = process_chunks(meta)\n",
    "\n",
    "end = time.process_time()\n",
    "elapsed_time = end - start\n",
    "print('Created a subset of the meta dataset')\n",
    "print('Execution time:', elapsed_time, 'seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54459d30-0e0f-4b8b-be54-26d88bec01eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>images</th>\n",
       "      <th>asin</th>\n",
       "      <th>parent_asin</th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>helpful_vote</th>\n",
       "      <th>verified_purchase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Received Used &amp; scratched item! Purchased new!</td>\n",
       "      <td>Livid.  Once again received an obviously used ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>B007WQ9YNO</td>\n",
       "      <td>B09XWYG6X1</td>\n",
       "      <td>AFKZENTNBQ7A7V7UXW5JJI6UGRYQ</td>\n",
       "      <td>2023-02-26 01:03:29.298</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Excellent for moving &amp; storage &amp; floods!</td>\n",
       "      <td>I purchased these for multiple reasons. The ma...</td>\n",
       "      <td>[]</td>\n",
       "      <td>B09H2VJW6K</td>\n",
       "      <td>B0BXDLF8TW</td>\n",
       "      <td>AFKZENTNBQ7A7V7UXW5JJI6UGRYQ</td>\n",
       "      <td>2022-12-26 08:30:10.846</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Lid very loose- needs a gasket imo. Small base.</td>\n",
       "      <td>[[VIDEOID:c87e962bc893a948856b0f1b285ce6cc]] I...</td>\n",
       "      <td>[{'small_image_url': 'https://m.media-amazon.c...</td>\n",
       "      <td>B07RL297VR</td>\n",
       "      <td>B09G2PW8ZG</td>\n",
       "      <td>AFKZENTNBQ7A7V7UXW5JJI6UGRYQ</td>\n",
       "      <td>2022-05-25 02:54:56.788</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rating                                            title  \\\n",
       "0       1   Received Used & scratched item! Purchased new!   \n",
       "1       5         Excellent for moving & storage & floods!   \n",
       "2       2  Lid very loose- needs a gasket imo. Small base.   \n",
       "\n",
       "                                                text  \\\n",
       "0  Livid.  Once again received an obviously used ...   \n",
       "1  I purchased these for multiple reasons. The ma...   \n",
       "2  [[VIDEOID:c87e962bc893a948856b0f1b285ce6cc]] I...   \n",
       "\n",
       "                                              images        asin parent_asin  \\\n",
       "0                                                 []  B007WQ9YNO  B09XWYG6X1   \n",
       "1                                                 []  B09H2VJW6K  B0BXDLF8TW   \n",
       "2  [{'small_image_url': 'https://m.media-amazon.c...  B07RL297VR  B09G2PW8ZG   \n",
       "\n",
       "                        user_id               timestamp  helpful_vote  \\\n",
       "0  AFKZENTNBQ7A7V7UXW5JJI6UGRYQ 2023-02-26 01:03:29.298             1   \n",
       "1  AFKZENTNBQ7A7V7UXW5JJI6UGRYQ 2022-12-26 08:30:10.846             0   \n",
       "2  AFKZENTNBQ7A7V7UXW5JJI6UGRYQ 2022-05-25 02:54:56.788             0   \n",
       "\n",
       "   verified_purchase  \n",
       "0               True  \n",
       "1               True  \n",
       "2               True  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_subset.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72cc77c3-d099-4286-9ad9-a0ac30021156",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['rating', 'title', 'text', 'images', 'asin', 'parent_asin', 'user_id',\n",
       "       'timestamp', 'helpful_vote', 'verified_purchase'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_subset.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a4d30c-c991-4605-be1f-c9b401061210",
   "metadata": {},
   "source": [
    "## Bing Liu Lexicon - NLTK\n",
    "\n",
    "The Bing Liu lexicon has a total of 6, 786 words with 2,005 classified as positive and 4,781 as negative. CLassification is binary (positive or negative)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5887a47-ad06-4241-b7ce-5fa7f40bd806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of words in opinion lexicon 6789\n",
      "Examples of positive words: ['a+', 'abound', 'abounds', 'abundance', 'abundant', 'accessable', 'accessible', 'acclaim', 'acclaimed', 'acclamation']\n",
      "Examples of negative words: ['2-faced', '2-faces', 'abnormal', 'abolish', 'abominable', 'abominably', 'abominate', 'abomination', 'abort', 'aborted']\n"
     ]
    }
   ],
   "source": [
    "print('Total number of words in opinion lexicon', len(opinion_lexicon.words()))\n",
    "print('Examples of positive words:', opinion_lexicon.positive()[:10])\n",
    "print('Examples of negative words:', opinion_lexicon.negative()[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41e75ef3-dbe2-493f-86a5-91a5a010d001",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_score = 1\n",
    "neg_score = -1\n",
    "word_dict = {}\n",
    "\n",
    "# Adding the positive words to the dictionary\n",
    "for word in opinion_lexicon.positive():\n",
    "    word_dict[word] = pos_score \n",
    "\n",
    "# Adding the negative words to the dictionary \n",
    "for word in opinion_lexicon.negative():\n",
    "    word_dict[word] = neg_score \n",
    "\n",
    "def bing_liu_score(text):\n",
    "    sentiment_score = 0 \n",
    "    bag_of_words = word_tokenize(text.lower())\n",
    "\n",
    "    # Check if bag_of_words is empty\n",
    "    if bag_of_words: \n",
    "        for word in bag_of_words: \n",
    "            if word in word_dict: \n",
    "                sentiment_score += word_dict[word]\n",
    "        return sentiment_score / len(bag_of_words)\n",
    "    else: \n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91a39dd6-e6a5-4996-9102-8a7131a4cc02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>text</th>\n",
       "      <th>asin</th>\n",
       "      <th>Bing_Liu_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>88819</th>\n",
       "      <td>4</td>\n",
       "      <td>Not much different than other celebratory cand...</td>\n",
       "      <td>B001L7XA6M</td>\n",
       "      <td>0.081633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52653</th>\n",
       "      <td>5</td>\n",
       "      <td>[[VIDEOID:cc3f0f3e321b523f577431a4b0a8da46]] D...</td>\n",
       "      <td>B088GG43CJ</td>\n",
       "      <td>0.087500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65678</th>\n",
       "      <td>5</td>\n",
       "      <td>doesn't leak! Holds temperature exactly like i...</td>\n",
       "      <td>B00KR9OQE0</td>\n",
       "      <td>0.078947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95552</th>\n",
       "      <td>5</td>\n",
       "      <td>UPDATE&lt;br /&gt;I've been using this vacuum almost...</td>\n",
       "      <td>B07C5MXJMX</td>\n",
       "      <td>0.054054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74545</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect “in between” size hangers</td>\n",
       "      <td>B07FK4BGXZ</td>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       rating                                               text        asin  \\\n",
       "88819       4  Not much different than other celebratory cand...  B001L7XA6M   \n",
       "52653       5  [[VIDEOID:cc3f0f3e321b523f577431a4b0a8da46]] D...  B088GG43CJ   \n",
       "65678       5  doesn't leak! Holds temperature exactly like i...  B00KR9OQE0   \n",
       "95552       5  UPDATE<br />I've been using this vacuum almost...  B07C5MXJMX   \n",
       "74545       5                  Perfect “in between” size hangers  B07FK4BGXZ   \n",
       "\n",
       "       Bing_Liu_Score  \n",
       "88819        0.081633  \n",
       "52653        0.087500  \n",
       "65678        0.078947  \n",
       "95552        0.054054  \n",
       "74545        0.142857  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_scores = reviews_subset.copy()\n",
    "sentiment_scores['Bing_Liu_Score'] = sentiment_scores['text'].apply(bing_liu_score)\n",
    "sentiment_scores[['rating', 'text', 'asin', 'Bing_Liu_Score']].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc64278e-05c5-4666-93dd-788f93858bea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Bing_Liu_Score\n",
      "rating                \n",
      "1            -0.020034\n",
      "2             0.004955\n",
      "3             0.026585\n",
      "4             0.069269\n",
      "5             0.116748\n"
     ]
    }
   ],
   "source": [
    "# Calculate mean sentiment score for each rating category\n",
    "accuracy_scores = sentiment_scores.groupby('rating').agg({'Bing_Liu_Score':'mean'})\n",
    "\n",
    "print(accuracy_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4291b896-3b1b-4c16-bd45-0d7890b08f86",
   "metadata": {},
   "source": [
    "## VADER Lexicon\n",
    "Rule-based lexicon. \n",
    "9,000 features with scales of [-4] Extremely Negative to [4] Extremely Positive with [0] for Neutral or Neither. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e75ea6-5546-46fa-b399-9bb22534db27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
